{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The goals of this notebook:\n",
    "* Train a unconstrained neural network model to classify kidney Cancer using Deep Learning (Tensorflow and Keras) and the UCI Chronic Kidney Disease dataset.\n",
    "* Evaluate model performance specifically, Recall, overall as well across age groups. This will demonstrate that a good model overall can suffer significantly when looked at from the lens of age. This can lead to loss-of-life when applied to an age group for which the model perfoms poorly.\n",
    "* Set up a constrained optimization problem to achieve consistent Recall across age groups using the Lagrangian Optimizer and Tensorflow Constrained Optimization.\n",
    "* Retrain the now constrained model and evaluate performance again, ensuring that our fairness metric (Recall) has been improved across age groups. At the very least, limitations of the model across age groups is highlighted and directly optimized for during model training.\n",
    "\n",
    "Dataset: https://archive.ics.uci.edu/ml/datasets/chronic_kidney_disease\n",
    "\n",
    "Some tutorial articles using this dataset:\n",
    "\n",
    "* https://mclguide.readthedocs.io/en/latest/sklearn/preprocessing.html#chronic-kidney-disease\n",
    "* https://randerson112358.medium.com/chronic-kidney-disease-prediction-detection-using-machine-learning-29cc7e3eba96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 1;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /Users/badri/opt/anaconda3/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"import glob\\nfrom keras.models import Sequential, load_model\\nimport numpy as np\\nimport pandas as pd\\nimport keras as k\\nfrom keras.layers import Dense\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import LabelEncoder\\nimport matplotlib.pyplot as plt\\nimport tensorflow as tf\";\n",
       "                var nbb_formatted_code = \"import glob\\nfrom keras.models import Sequential, load_model\\nimport numpy as np\\nimport pandas as pd\\nimport keras as k\\nfrom keras.layers import Dense\\nfrom sklearn.model_selection import train_test_split\\nfrom sklearn.preprocessing import LabelEncoder\\nimport matplotlib.pyplot as plt\\nimport tensorflow as tf\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import glob\n",
    "from keras.models import Sequential, load_model\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras as k\n",
    "from keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Reproducibility\\ndef set_seeds():\\n    np.random.seed(121212)\\n    tf.compat.v1.set_random_seed(212121)\\n\\n\\nset_seeds()\";\n",
       "                var nbb_formatted_code = \"# Reproducibility\\ndef set_seeds():\\n    np.random.seed(121212)\\n    tf.compat.v1.set_random_seed(212121)\\n\\n\\nset_seeds()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reproducibility\n",
    "def set_seeds():\n",
    "    np.random.seed(121212)\n",
    "    tf.compat.v1.set_random_seed(212121)\n",
    "\n",
    "\n",
    "set_seeds()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>?</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>?</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>?</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  bp     sg al su     rbc        pc         pcc          ba  bgr  ...  \\\n",
       "0  48  80  1.020  1  0       ?    normal  notpresent  notpresent  121  ...   \n",
       "1   7  50  1.020  4  0       ?    normal  notpresent  notpresent    ?  ...   \n",
       "2  62  80  1.010  2  3  normal    normal  notpresent  notpresent  423  ...   \n",
       "3  48  70  1.005  4  0  normal  abnormal     present  notpresent  117  ...   \n",
       "4  51  80  1.010  2  0  normal    normal  notpresent  notpresent  106  ...   \n",
       "\n",
       "  pcv  wbcc rbcc  htn   dm cad appet   pe  ane classification  \n",
       "0  44  7800  5.2  yes  yes  no  good   no   no            ckd  \n",
       "1  38  6000    ?   no   no  no  good   no   no            ckd  \n",
       "2  31  7500    ?   no  yes  no  poor   no  yes            ckd  \n",
       "3  32  6700  3.9  yes   no  no  poor  yes  yes            ckd  \n",
       "4  35  7300  4.6   no   no  no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"# create header for dataset\\nheader = [\\n    \\\"age\\\",\\n    \\\"bp\\\",\\n    \\\"sg\\\",\\n    \\\"al\\\",\\n    \\\"su\\\",\\n    \\\"rbc\\\",\\n    \\\"pc\\\",\\n    \\\"pcc\\\",\\n    \\\"ba\\\",\\n    \\\"bgr\\\",\\n    \\\"bu\\\",\\n    \\\"sc\\\",\\n    \\\"sod\\\",\\n    \\\"pot\\\",\\n    \\\"hemo\\\",\\n    \\\"pcv\\\",\\n    \\\"wbcc\\\",\\n    \\\"rbcc\\\",\\n    \\\"htn\\\",\\n    \\\"dm\\\",\\n    \\\"cad\\\",\\n    \\\"appet\\\",\\n    \\\"pe\\\",\\n    \\\"ane\\\",\\n    \\\"classification\\\",\\n]\\n# read the dataset\\ndf = pd.read_csv(\\\"chronic_kidney_disease.csv\\\", header=None, names=header)\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"# create header for dataset\\nheader = [\\n    \\\"age\\\",\\n    \\\"bp\\\",\\n    \\\"sg\\\",\\n    \\\"al\\\",\\n    \\\"su\\\",\\n    \\\"rbc\\\",\\n    \\\"pc\\\",\\n    \\\"pcc\\\",\\n    \\\"ba\\\",\\n    \\\"bgr\\\",\\n    \\\"bu\\\",\\n    \\\"sc\\\",\\n    \\\"sod\\\",\\n    \\\"pot\\\",\\n    \\\"hemo\\\",\\n    \\\"pcv\\\",\\n    \\\"wbcc\\\",\\n    \\\"rbcc\\\",\\n    \\\"htn\\\",\\n    \\\"dm\\\",\\n    \\\"cad\\\",\\n    \\\"appet\\\",\\n    \\\"pe\\\",\\n    \\\"ane\\\",\\n    \\\"classification\\\",\\n]\\n# read the dataset\\ndf = pd.read_csv(\\\"chronic_kidney_disease.csv\\\", header=None, names=header)\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create header for dataset\n",
    "header = [\n",
    "    \"age\",\n",
    "    \"bp\",\n",
    "    \"sg\",\n",
    "    \"al\",\n",
    "    \"su\",\n",
    "    \"rbc\",\n",
    "    \"pc\",\n",
    "    \"pcc\",\n",
    "    \"ba\",\n",
    "    \"bgr\",\n",
    "    \"bu\",\n",
    "    \"sc\",\n",
    "    \"sod\",\n",
    "    \"pot\",\n",
    "    \"hemo\",\n",
    "    \"pcv\",\n",
    "    \"wbcc\",\n",
    "    \"rbcc\",\n",
    "    \"htn\",\n",
    "    \"dm\",\n",
    "    \"cad\",\n",
    "    \"appet\",\n",
    "    \"pe\",\n",
    "    \"ane\",\n",
    "    \"classification\",\n",
    "]\n",
    "# read the dataset\n",
    "df = pd.read_csv(\"chronic_kidney_disease.csv\", header=None, names=header)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleansing and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>bp</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>su</th>\n",
       "      <th>rbc</th>\n",
       "      <th>pc</th>\n",
       "      <th>pcc</th>\n",
       "      <th>ba</th>\n",
       "      <th>bgr</th>\n",
       "      <th>...</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>dm</th>\n",
       "      <th>cad</th>\n",
       "      <th>appet</th>\n",
       "      <th>pe</th>\n",
       "      <th>ane</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48</td>\n",
       "      <td>80</td>\n",
       "      <td>1.020</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>44</td>\n",
       "      <td>7800</td>\n",
       "      <td>5.2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>50</td>\n",
       "      <td>1.020</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>6000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>423</td>\n",
       "      <td>...</td>\n",
       "      <td>31</td>\n",
       "      <td>7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>70</td>\n",
       "      <td>1.005</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>present</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>117</td>\n",
       "      <td>...</td>\n",
       "      <td>32</td>\n",
       "      <td>6700</td>\n",
       "      <td>3.9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>poor</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51</td>\n",
       "      <td>80</td>\n",
       "      <td>1.010</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "      <td>normal</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>notpresent</td>\n",
       "      <td>106</td>\n",
       "      <td>...</td>\n",
       "      <td>35</td>\n",
       "      <td>7300</td>\n",
       "      <td>4.6</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>good</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>ckd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  bp     sg al su     rbc        pc         pcc          ba  bgr  ...  \\\n",
       "0  48  80  1.020  1  0     NaN    normal  notpresent  notpresent  121  ...   \n",
       "1   7  50  1.020  4  0     NaN    normal  notpresent  notpresent  NaN  ...   \n",
       "2  62  80  1.010  2  3  normal    normal  notpresent  notpresent  423  ...   \n",
       "3  48  70  1.005  4  0  normal  abnormal     present  notpresent  117  ...   \n",
       "4  51  80  1.010  2  0  normal    normal  notpresent  notpresent  106  ...   \n",
       "\n",
       "  pcv  wbcc rbcc  htn   dm cad appet   pe  ane classification  \n",
       "0  44  7800  5.2  yes  yes  no  good   no   no            ckd  \n",
       "1  38  6000  NaN   no   no  no  good   no   no            ckd  \n",
       "2  31  7500  NaN   no  yes  no  poor   no  yes            ckd  \n",
       "3  32  6700  3.9  yes   no  no  poor  yes  yes            ckd  \n",
       "4  35  7300  4.6   no   no  no  good   no   no            ckd  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Some preprocessing to remove '?', replace TABS, NaNs etc.,\\n# df.replace(\\\"Nan\\\", np.nan, inplace=True)\\n# df.replace(\\\"\\\\t?\\\", np.nan, inplace=True)\\ndf.replace(\\\"?\\\", np.nan, inplace=True)\\ndf.classification.replace(\\\"ckd\\\\t\\\", \\\"ckd\\\", inplace=True)\\ndf.head()\";\n",
       "                var nbb_formatted_code = \"# Some preprocessing to remove '?', replace TABS, NaNs etc.,\\n# df.replace(\\\"Nan\\\", np.nan, inplace=True)\\n# df.replace(\\\"\\\\t?\\\", np.nan, inplace=True)\\ndf.replace(\\\"?\\\", np.nan, inplace=True)\\ndf.classification.replace(\\\"ckd\\\\t\\\", \\\"ckd\\\", inplace=True)\\ndf.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Some preprocessing to remove '?', replace TABS, NaNs etc.,\n",
    "# df.replace(\"Nan\", np.nan, inplace=True)\n",
    "# df.replace(\"\\t?\", np.nan, inplace=True)\n",
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.classification.replace(\"ckd\\t\", \"ckd\", inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"# Create a list of columns to retain\\ncolumns_to_retain = [\\n    \\\"age\\\",\\n    \\\"sg\\\",\\n    \\\"al\\\",\\n    \\\"sc\\\",\\n    \\\"hemo\\\",\\n    \\\"pcv\\\",\\n    \\\"wbcc\\\",\\n    \\\"rbcc\\\",\\n    \\\"htn\\\",\\n    \\\"classification\\\",\\n]\\n\\n# columns_to_retain = df.columns, Drop the columns that are not in columns_to_retain\\ndf = df.drop([col for col in df.columns if not col in columns_to_retain], axis=1)\";\n",
       "                var nbb_formatted_code = \"# Create a list of columns to retain\\ncolumns_to_retain = [\\n    \\\"age\\\",\\n    \\\"sg\\\",\\n    \\\"al\\\",\\n    \\\"sc\\\",\\n    \\\"hemo\\\",\\n    \\\"pcv\\\",\\n    \\\"wbcc\\\",\\n    \\\"rbcc\\\",\\n    \\\"htn\\\",\\n    \\\"classification\\\",\\n]\\n\\n# columns_to_retain = df.columns, Drop the columns that are not in columns_to_retain\\ndf = df.drop([col for col in df.columns if not col in columns_to_retain], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a list of columns to retain\n",
    "columns_to_retain = [\n",
    "    \"age\",\n",
    "    \"sg\",\n",
    "    \"al\",\n",
    "    \"sc\",\n",
    "    \"hemo\",\n",
    "    \"pcv\",\n",
    "    \"wbcc\",\n",
    "    \"rbcc\",\n",
    "    \"htn\",\n",
    "    \"classification\",\n",
    "]\n",
    "\n",
    "# columns_to_retain = df.columns, Drop the columns that are not in columns_to_retain\n",
    "df = df.drop([col for col in df.columns if not col in columns_to_retain], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Drop the rows with na or missing values\\n# Do this here instead of earlier so that we do not unnecessarily drop rows which have NaN or empty values for\\n# columns which we do not use.\\ndf = df.dropna(axis=0)\";\n",
       "                var nbb_formatted_code = \"# Drop the rows with na or missing values\\n# Do this here instead of earlier so that we do not unnecessarily drop rows which have NaN or empty values for\\n# columns which we do not use.\\ndf = df.dropna(axis=0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Drop the rows with na or missing values\n",
    "# Do this here instead of earlier so that we do not unnecessarily drop rows which have NaN or empty values for\n",
    "# columns which we do not use.\n",
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"# convert the filtered columns to their appropriate datatypes\\n# df = df.astype(\\n#    {\\n#        \\\"age\\\": int,\\n#        \\\"sg\\\": float,\\n#        \\\"al\\\": int,\\n#        \\\"sc\\\": float,\\n#        \\\"hemo\\\": float,\\n#        \\\"pcv\\\": int,\\n#        \\\"wbcc\\\": int,\\n#        \\\"rbcc\\\": float,\\n#    }\\n# )\\ndf = df.astype(\\n    {\\n        \\\"age\\\": \\\"float32\\\",\\n        \\\"sg\\\": \\\"float32\\\",\\n        \\\"al\\\": \\\"float32\\\",\\n        \\\"sc\\\": \\\"float32\\\",\\n        \\\"hemo\\\": \\\"float32\\\",\\n        \\\"pcv\\\": \\\"float32\\\",\\n        \\\"wbcc\\\": \\\"float32\\\",\\n        \\\"rbcc\\\": \\\"float32\\\",\\n    }\\n)\";\n",
       "                var nbb_formatted_code = \"# convert the filtered columns to their appropriate datatypes\\n# df = df.astype(\\n#    {\\n#        \\\"age\\\": int,\\n#        \\\"sg\\\": float,\\n#        \\\"al\\\": int,\\n#        \\\"sc\\\": float,\\n#        \\\"hemo\\\": float,\\n#        \\\"pcv\\\": int,\\n#        \\\"wbcc\\\": int,\\n#        \\\"rbcc\\\": float,\\n#    }\\n# )\\ndf = df.astype(\\n    {\\n        \\\"age\\\": \\\"float32\\\",\\n        \\\"sg\\\": \\\"float32\\\",\\n        \\\"al\\\": \\\"float32\\\",\\n        \\\"sc\\\": \\\"float32\\\",\\n        \\\"hemo\\\": \\\"float32\\\",\\n        \\\"pcv\\\": \\\"float32\\\",\\n        \\\"wbcc\\\": \\\"float32\\\",\\n        \\\"rbcc\\\": \\\"float32\\\",\\n    }\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the right datatypes\n",
    "df = df.astype(\n",
    "    {\n",
    "        \"age\": \"float32\",\n",
    "        \"sg\": \"float32\",\n",
    "        \"al\": \"float32\",\n",
    "        \"sc\": \"float32\",\n",
    "        \"hemo\": \"float32\",\n",
    "        \"pcv\": \"float32\",\n",
    "        \"wbcc\": \"float32\",\n",
    "        \"rbcc\": \"float32\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"# only keep values ckd or notckd for the target\\ndf.drop(df.index[df[\\\"classification\\\"] == \\\"no\\\"], inplace=True)\";\n",
       "                var nbb_formatted_code = \"# only keep values ckd or notckd for the target\\ndf.drop(df.index[df[\\\"classification\\\"] == \\\"no\\\"], inplace=True)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# only keep values ckd or notckd for the target\n",
    "df.drop(df.index[df[\"classification\"] == \"no\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"# Convert categorical target values to numeric.\\ntarget_encoding_values = {\\\"notckd\\\": 0, \\\"ckd\\\": 1}\\ndf[\\\"classification\\\"] = df[\\\"classification\\\"].apply(\\n    lambda x: target_encoding_values.get(x)\\n)\\ndf = df.astype({\\\"classification\\\": \\\"float32\\\"})\";\n",
       "                var nbb_formatted_code = \"# Convert categorical target values to numeric.\\ntarget_encoding_values = {\\\"notckd\\\": 0, \\\"ckd\\\": 1}\\ndf[\\\"classification\\\"] = df[\\\"classification\\\"].apply(\\n    lambda x: target_encoding_values.get(x)\\n)\\ndf = df.astype({\\\"classification\\\": \\\"float32\\\"})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert categorical target values to numeric.\n",
    "target_encoding_values = {\"notckd\": 0, \"ckd\": 1}\n",
    "df[\"classification\"] = df[\"classification\"].apply(\n",
    "    lambda x: target_encoding_values.get(x)\n",
    ")\n",
    "df = df.astype({\"classification\": \"float32\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/badri/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Converting `np.inexact` or `np.floating` to a dtype is deprecated. The current result is `float64` which is not strictly correct.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"# Transform non-numeric columns into numerical columns\\nfor column in df.columns:\\n    if df[column].dtype != np.number:\\n        df[column] = LabelEncoder().fit_transform(df[column])\";\n",
       "                var nbb_formatted_code = \"# Transform non-numeric columns into numerical columns\\nfor column in df.columns:\\n    if df[column].dtype != np.number:\\n        df[column] = LabelEncoder().fit_transform(df[column])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transform non-numeric columns into numerical columns\n",
    "for column in df.columns:\n",
    "    if df[column].dtype != np.number:\n",
    "        df[column] = LabelEncoder().fit_transform(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"df[\\\"Young\\\"] = df[\\\"age\\\"] <= 28\\ndf = df.astype({\\\"Young\\\": \\\"float32\\\"})\";\n",
       "                var nbb_formatted_code = \"df[\\\"Young\\\"] = df[\\\"age\\\"] <= 28\\ndf = df.astype({\\\"Young\\\": \\\"float32\\\"})\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"Young\"] = df[\"age\"] <= 28\n",
    "df = df.astype({\"Young\": \"float32\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>sc</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>classification</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "      <td>235.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>35.012766</td>\n",
       "      <td>2.689362</td>\n",
       "      <td>0.859574</td>\n",
       "      <td>13.880851</td>\n",
       "      <td>53.263830</td>\n",
       "      <td>22.229787</td>\n",
       "      <td>37.302128</td>\n",
       "      <td>23.502128</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.455319</td>\n",
       "      <td>0.314894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.890334</td>\n",
       "      <td>1.140407</td>\n",
       "      <td>1.356160</td>\n",
       "      <td>14.781408</td>\n",
       "      <td>24.783304</td>\n",
       "      <td>8.634950</td>\n",
       "      <td>19.739278</td>\n",
       "      <td>9.663737</td>\n",
       "      <td>0.474864</td>\n",
       "      <td>0.499063</td>\n",
       "      <td>0.465465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>46.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>18.500000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>97.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>82.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age          sg          al          sc        hemo         pcv  \\\n",
       "count  235.000000  235.000000  235.000000  235.000000  235.000000  235.000000   \n",
       "mean    35.012766    2.689362    0.859574   13.880851   53.263830   22.229787   \n",
       "std     14.890334    1.140407    1.356160   14.781408   24.783304    8.634950   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%     25.000000    2.000000    0.000000    4.000000   34.000000   16.000000   \n",
       "50%     38.000000    3.000000    0.000000    8.000000   56.000000   23.000000   \n",
       "75%     46.000000    4.000000    2.000000   18.500000   72.000000   29.000000   \n",
       "max     64.000000    4.000000    5.000000   60.000000   97.000000   36.000000   \n",
       "\n",
       "             wbcc        rbcc         htn  classification       Young  \n",
       "count  235.000000  235.000000  235.000000      235.000000  235.000000  \n",
       "mean    37.302128   23.502128    0.340426        0.455319    0.314894  \n",
       "std     19.739278    9.663737    0.474864        0.499063    0.465465  \n",
       "min      0.000000    0.000000    0.000000        0.000000    0.000000  \n",
       "25%     23.000000   16.000000    0.000000        0.000000    0.000000  \n",
       "50%     36.000000   24.000000    0.000000        0.000000    0.000000  \n",
       "75%     52.000000   30.500000    1.000000        1.000000    1.000000  \n",
       "max     82.000000   42.000000    1.000000        1.000000    1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"df.describe()\";\n",
       "                var nbb_formatted_code = \"df.describe()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sg</th>\n",
       "      <th>al</th>\n",
       "      <th>sc</th>\n",
       "      <th>hemo</th>\n",
       "      <th>pcv</th>\n",
       "      <th>wbcc</th>\n",
       "      <th>rbcc</th>\n",
       "      <th>htn</th>\n",
       "      <th>classification</th>\n",
       "      <th>Young</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>73</td>\n",
       "      <td>26</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>31</td>\n",
       "      <td>35</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>39</td>\n",
       "      <td>17</td>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>44</td>\n",
       "      <td>21</td>\n",
       "      <td>34</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sg  al  sc  hemo  pcv  wbcc  rbcc  htn  classification  Young\n",
       "0   31   3   1   8    73   26    34    28    1               1    0.0\n",
       "3   31   0   4  31    35   14    24    15    1               1    0.0\n",
       "4   34   1   2  10    39   17    30    22    0               1    0.0\n",
       "5   43   2   3   7    44   21    34    20    1               1    0.0\n",
       "7    9   2   2   7    45   26    26    26    0               1    1.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"df.head()\";\n",
       "                var nbb_formatted_code = \"df.head()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                8228.0\n",
       "sg                  632.0\n",
       "al                  202.0\n",
       "sc                 3262.0\n",
       "hemo              12517.0\n",
       "pcv                5224.0\n",
       "wbcc               8766.0\n",
       "rbcc               5523.0\n",
       "htn                  80.0\n",
       "classification      107.0\n",
       "Young                74.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"df.sum()\";\n",
       "                var nbb_formatted_code = \"df.sum()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data split and augmentation for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"# Split the data\\nX = df.drop([\\\"classification\\\"], axis=1)\\ny = df[\\\"classification\\\"]\";\n",
       "                var nbb_formatted_code = \"# Split the data\\nX = df.drop([\\\"classification\\\"], axis=1)\\ny = df[\\\"classification\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data\n",
    "X = df.drop([\"classification\"], axis=1)\n",
    "y = df[\"classification\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"# Split the data\\ntest_size = 0.3\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=test_size, shuffle=True\\n)\";\n",
       "                var nbb_formatted_code = \"# Split the data\\ntest_size = 0.3\\nX_train, X_test, y_train, y_test = train_test_split(\\n    X, y, test_size=test_size, shuffle=True\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split the data\n",
    "test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# Separate the \\\"Young\\\" attribute into a group attribute\\ngroup_train = X_train[\\\"Young\\\"]\\nX_train = X_train.drop([\\\"Young\\\"], axis=1)\\n\\ngroup_test = X_test[\\\"Young\\\"]\\nX_test = X_test.drop([\\\"Young\\\"], axis=1)\";\n",
       "                var nbb_formatted_code = \"# Separate the \\\"Young\\\" attribute into a group attribute\\ngroup_train = X_train[\\\"Young\\\"]\\nX_train = X_train.drop([\\\"Young\\\"], axis=1)\\n\\ngroup_test = X_test[\\\"Young\\\"]\\nX_test = X_test.drop([\\\"Young\\\"], axis=1)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Separate the \"Young\" attribute into a group attribute\n",
    "group_train = X_train[\"Young\"]\n",
    "X_train = X_train.drop([\"Young\"], axis=1)\n",
    "\n",
    "group_test = X_test[\"Young\"]\n",
    "X_test = X_test.drop([\"Young\"], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Original model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"# Define custom recall metric to be tracked\\nfrom keras import backend as K\\n\\n\\ndef recall_m(y_true, y_pred):\\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\\n    recall = true_positives / (possible_positives + K.epsilon())\\n    return recall\";\n",
       "                var nbb_formatted_code = \"# Define custom recall metric to be tracked\\nfrom keras import backend as K\\n\\n\\ndef recall_m(y_true, y_pred):\\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\\n    recall = true_positives / (possible_positives + K.epsilon())\\n    return recall\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define custom recall metric to be tracked\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and train the original model\n",
    "\n",
    "* Use ADAM optimizer with learning rate 0.001\n",
    "* TFCO uses hinge loss by default and so that will be used.\n",
    "* Accuracy and recall are both tracked as metrics.\n",
    "* Train for n_epochs\n",
    "* Stop when loss stops decreasing after 'loss_patience' = 5 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"# Build The model. The simple model consists of:\\n# 1. An input layer that represents the X\\n# 2. A fully connected layer with 16 units activated by a ReLU function.\\n# 3. A single-unit readout layer to output real-scores instead of probabilities.\\n\\n\\ndef create_model():\\n    model = Sequential()\\n    model.add(\\n        Dense(\\n            16,\\n            input_dim=len(X_train.columns),\\n            kernel_initializer=k.initializers.random_normal(seed=13),\\n            activation=\\\"relu\\\",\\n        )\\n    )\\n    # Return raw output scores for TFCO assessment.\\n    # Original:\\n    # model.add(Dense(1, activation=\\\"sigmoid\\\"))\\n    model.add(Dense(1, activation=None))\\n\\n    # Compile the model - original\\n    # model.compile(\\n    #    loss=\\\"binary_crossentropy\\\", optimizer=\\\"adam\\\", metrics=[\\\"accuracy\\\", recall_m]\\n    # )\\n\\n    # TFCO by default uses hinge loss \\u2014 and that will also be used in the model.\\n    model.compile(\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n        loss=\\\"hinge\\\",\\n        metrics=[\\\"accuracy\\\", recall_m],\\n    )\\n\\n    return model\";\n",
       "                var nbb_formatted_code = \"# Build The model. The simple model consists of:\\n# 1. An input layer that represents the X\\n# 2. A fully connected layer with 16 units activated by a ReLU function.\\n# 3. A single-unit readout layer to output real-scores instead of probabilities.\\n\\n\\ndef create_model():\\n    model = Sequential()\\n    model.add(\\n        Dense(\\n            16,\\n            input_dim=len(X_train.columns),\\n            kernel_initializer=k.initializers.random_normal(seed=13),\\n            activation=\\\"relu\\\",\\n        )\\n    )\\n    # Return raw output scores for TFCO assessment.\\n    # Original:\\n    # model.add(Dense(1, activation=\\\"sigmoid\\\"))\\n    model.add(Dense(1, activation=None))\\n\\n    # Compile the model - original\\n    # model.compile(\\n    #    loss=\\\"binary_crossentropy\\\", optimizer=\\\"adam\\\", metrics=[\\\"accuracy\\\", recall_m]\\n    # )\\n\\n    # TFCO by default uses hinge loss \\u2014 and that will also be used in the model.\\n    model.compile(\\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n        loss=\\\"hinge\\\",\\n        metrics=[\\\"accuracy\\\", recall_m],\\n    )\\n\\n    return model\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build The model. The model consists of:\n",
    "# 1. An input layer that represents the X\n",
    "# 2. A fully connected layer with 16 units activated by a ReLU function.\n",
    "# 3. A single-unit readout layer to output real-scores instead of probabilities.\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(\n",
    "        Dense(\n",
    "            16,\n",
    "            input_dim=len(X_train.columns),\n",
    "            kernel_initializer=k.initializers.random_normal(seed=13),\n",
    "            activation=\"relu\",\n",
    "        )\n",
    "    )\n",
    "    # Return raw output scores for TFCO assessment.\n",
    "    # Original:\n",
    "    # model.add(Dense(1, activation=\"sigmoid\"))\n",
    "    model.add(Dense(1, activation=None))\n",
    "\n",
    "    # Compile the model - original\n",
    "    # model.compile(\n",
    "    #    loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\", recall_m]\n",
    "    # )\n",
    "\n",
    "    # TFCO by default uses hinge loss — and that will also be used in the model.\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "        loss=\"hinge\",\n",
    "        metrics=[\"accuracy\", recall_m],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"model = create_model()\";\n",
       "                var nbb_formatted_code = \"model = create_model()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "1/1 [==============================] - 1s 579ms/step - loss: 2.4732 - accuracy: 0.5366 - recall_m: 0.0000e+00\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.2884 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 2.1027 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.9165 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.7313 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.5459 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.3612 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.1813 - accuracy: 0.5427 - recall_m: 0.0132\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 1.0343 - accuracy: 0.5549 - recall_m: 0.0395\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.9341 - accuracy: 0.5488 - recall_m: 0.0526\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8796 - accuracy: 0.5671 - recall_m: 0.0921\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.8524 - accuracy: 0.5732 - recall_m: 0.1579\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.8179 - accuracy: 0.5915 - recall_m: 0.2500\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.7759 - accuracy: 0.6098 - recall_m: 0.3553\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.7225 - accuracy: 0.6707 - recall_m: 0.5000\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.6592 - accuracy: 0.7561 - recall_m: 0.6711\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5888 - accuracy: 0.7927 - recall_m: 0.7105\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5172 - accuracy: 0.8232 - recall_m: 0.7632\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4463 - accuracy: 0.8293 - recall_m: 0.7368\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.3826 - accuracy: 0.8720 - recall_m: 0.7500\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.3317 - accuracy: 0.8780 - recall_m: 0.7500\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2942 - accuracy: 0.8780 - recall_m: 0.7368\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8598 - recall_m: 0.6974\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2574 - accuracy: 0.8659 - recall_m: 0.7105\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2541 - accuracy: 0.8659 - recall_m: 0.7105\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2521 - accuracy: 0.8659 - recall_m: 0.7105\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2491 - accuracy: 0.8720 - recall_m: 0.7237\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.2441 - accuracy: 0.8780 - recall_m: 0.7368\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.8780 - recall_m: 0.7368\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.2329 - accuracy: 0.8841 - recall_m: 0.7500\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2267 - accuracy: 0.8841 - recall_m: 0.7500\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.8841 - recall_m: 0.7500\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.2149 - accuracy: 0.8841 - recall_m: 0.7500\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2085 - accuracy: 0.8902 - recall_m: 0.7632\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.2024 - accuracy: 0.8963 - recall_m: 0.7763\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1977 - accuracy: 0.9024 - recall_m: 0.7895\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1947 - accuracy: 0.9085 - recall_m: 0.8026\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1939 - accuracy: 0.9146 - recall_m: 0.8158\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1949 - accuracy: 0.9207 - recall_m: 0.8289\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1954 - accuracy: 0.9268 - recall_m: 0.8553\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1956 - accuracy: 0.9268 - recall_m: 0.8553\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1949 - accuracy: 0.9268 - recall_m: 0.8553\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1932 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1905 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1873 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1842 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1820 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1795 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1793 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.1788 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1772 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1762 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1750 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1736 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1723 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1712 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1703 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1693 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1683 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1673 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1663 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1652 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1639 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1625 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1610 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1595 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1568 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 71/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1554 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1540 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1514 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1501 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1481 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1471 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1460 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1451 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1432 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1422 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1413 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1404 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1395 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1385 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1376 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1367 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1358 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1336 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1325 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1315 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1305 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1295 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1284 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1268 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1260 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1244 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1236 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1232 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1225 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1211 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1205 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1193 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1186 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1180 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1173 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1167 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1160 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1154 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1148 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1142 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1136 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1130 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 121/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1123 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1112 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1100 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1088 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 9ms/step - loss: 0.1078 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1072 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1068 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1063 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1058 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1048 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.1044 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1038 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1034 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1030 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 140/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.1021 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.1017 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.1010 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.1006 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1003 - accuracy: 0.9268 - recall_m: 0.8421\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.1000 - accuracy: 0.9329 - recall_m: 0.8553\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0997 - accuracy: 0.9390 - recall_m: 0.8684\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9390 - recall_m: 0.8684\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0992 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0988 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0982 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0979 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0975 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0974 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0970 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0969 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0965 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0962 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0962 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0957 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0954 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0953 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0948 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0944 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0941 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0939 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0936 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0933 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0927 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0924 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0919 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0914 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0911 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0907 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0904 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0902 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0899 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0897 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0892 - accuracy: 0.9451 - recall_m: 0.881 - 0s 3ms/step - loss: 0.0892 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0889 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0887 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0885 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0881 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0880 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0876 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0868 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0866 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0860 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0857 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0855 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0852 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0849 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0846 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0844 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0841 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0839 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0836 - accuracy: 0.9451 - recall_m: 0.8816\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0832 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0829 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0826 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0822 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0823 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0816 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0813 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0807 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0800 - accuracy: 0.9451 - recall_m: 0.8816\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0797 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0793 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0792 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0782 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0781 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0778 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0774 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0770 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0769 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0766 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0764 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0760 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0758 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0756 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0753 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0750 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0749 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0745 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0744 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0741 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0739 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0737 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0732 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0730 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0724 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0722 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0719 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0715 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0712 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0710 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0707 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0706 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0701 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0695 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0691 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0690 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0687 - accuracy: 0.9512 - recall_m: 0.8947\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0683 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0678 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0679 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0678 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0673 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0672 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 278/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0673 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0671 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0665 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0657 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0657 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0658 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0653 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0649 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0651 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0646 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0643 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0641 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0640 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0637 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0635 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0633 - accuracy: 0.9573 - recall_m: 0.9079\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0628 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0625 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0623 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0620 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0619 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0615 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0614 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.0612 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0607 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0604 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0602 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0599 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0594 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0592 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0590 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0588 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0587 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0585 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0583 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0581 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0580 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0578 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0578 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0574 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0575 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0575 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 16ms/step - loss: 0.0569 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0575 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0565 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0569 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0568 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0562 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0561 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0557 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0556 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0553 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0554 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0550 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 347/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0551 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0549 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0545 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0546 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0542 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0539 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0538 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0535 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0533 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0531 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0529 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0529 - accuracy: 0.9634 - recall_m: 0.9211\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0525 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0526 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0520 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0521 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0518 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9695 - recall_m: 0.934 - 0s 3ms/step - loss: 0.0511 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0510 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0509 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0507 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0504 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0503 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0502 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0500 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0498 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0496 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.0492 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0490 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0488 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0485 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0484 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0479 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0478 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0476 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.0475 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0475 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0474 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0473 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0471 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0468 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0469 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0464 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.0457 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0457 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9756 - recall_m: 0.9474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0452 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0451 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0446 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0447 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0445 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0442 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0439 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0436 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0435 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0432 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0431 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0430 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0429 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0428 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0428 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0427 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0421 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0424 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.0417 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0415 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0414 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0412 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0410 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0409 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 12ms/step - loss: 0.0408 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0404 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0403 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0400 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0397 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0400 - accuracy: 0.9695 - recall_m: 0.9342\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0393 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0397 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0394 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0389 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0389 - accuracy: 0.9756 - recall_m: 0.947 - 0s 8ms/step - loss: 0.0389 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0387 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0385 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0384 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0382 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0383 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0374 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0372 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0371 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0369 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0370 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9756 - recall_m: 0.947 - 0s 3ms/step - loss: 0.0368 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0366 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0365 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0363 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 484/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0359 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0358 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0356 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0352 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0355 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.0350 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0352 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0353 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0346 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.0343 - accuracy: 0.9756 - recall_m: 0.9474\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.0344 - accuracy: 0.9756 - recall_m: 0.9474\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 22;\n",
       "                var nbb_unformatted_code = \"# Train the model\\n\\n# Stop when loss stops decreasing after 'patience' epochs.\\n# See reference: https://keras.io/api/callbacks/early_stopping/\\nloss_patience = 5\\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(\\n    monitor=\\\"loss\\\", patience=loss_patience\\n)\\n\\nn_epochs = 500\\nhistory = model.fit(\\n    X_train,\\n    y_train,\\n    epochs=n_epochs,\\n    batch_size=X_train.shape[0],\\n    callbacks=[early_stopping_callback],\\n)\";\n",
       "                var nbb_formatted_code = \"# Train the model\\n\\n# Stop when loss stops decreasing after 'patience' epochs.\\n# See reference: https://keras.io/api/callbacks/early_stopping/\\nloss_patience = 5\\nearly_stopping_callback = tf.keras.callbacks.EarlyStopping(\\n    monitor=\\\"loss\\\", patience=loss_patience\\n)\\n\\nn_epochs = 500\\nhistory = model.fit(\\n    X_train,\\n    y_train,\\n    epochs=n_epochs,\\n    batch_size=X_train.shape[0],\\n    callbacks=[early_stopping_callback],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the model\n",
    "\n",
    "# Stop when loss stops decreasing after 'patience' epochs.\n",
    "# See reference: https://keras.io/api/callbacks/early_stopping/\n",
    "loss_patience = 5\n",
    "early_stopping_callback = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor=\"loss\", patience=loss_patience\n",
    ")\n",
    "\n",
    "n_epochs = 500\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=n_epochs,\n",
    "    batch_size=X_train.shape[0],\n",
    "    callbacks=[early_stopping_callback],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 51;\n",
       "                var nbb_unformatted_code = \"# Visualize the models accuracy and loss\\nplt.plot(history.history[\\\"accuracy\\\"])\\nplt.plot(history.history[\\\"recall_m\\\"])\\n# plt.plot(history.history[\\\"loss\\\"])\\nplt.title(\\\"model accuracy, recall & loss\\\")\\nplt.ylabel(\\\"accuracy, recall, loss\\\")\\nplt.xlabel(\\\"epoch\\\")\\nplt.legend([\\\"accuracy\\\", \\\"recall_m\\\", \\\"loss\\\"], loc=\\\"lower right\\\")\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Visualize the models accuracy and loss\\nplt.plot(history.history[\\\"accuracy\\\"])\\nplt.plot(history.history[\\\"recall_m\\\"])\\n# plt.plot(history.history[\\\"loss\\\"])\\nplt.title(\\\"model accuracy, recall & loss\\\")\\nplt.ylabel(\\\"accuracy, recall, loss\\\")\\nplt.xlabel(\\\"epoch\\\")\\nplt.legend([\\\"accuracy\\\", \\\"recall_m\\\", \\\"loss\\\"], loc=\\\"lower right\\\")\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the models accuracy and loss\n",
    "plt.plot(history.history[\"accuracy\"])\n",
    "plt.plot(history.history[\"recall_m\"])\n",
    "# plt.plot(history.history[\"loss\"])\n",
    "plt.title(\"model accuracy, recall & loss\")\n",
    "plt.ylabel(\"accuracy, recall, loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"accuracy\", \"recall_m\", \"loss\"], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 24;\n",
       "                var nbb_unformatted_code = \"# Prediction\\npred = model.predict(X_test)\";\n",
       "                var nbb_formatted_code = \"# Prediction\\npred = model.predict(X_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prediction\n",
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 1ms/step - loss: 0.0838 - accuracy: 0.9859 - recall_m: 0.9762\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"# Evaluate on test set\\nscores = model.evaluate(X_test, y_test)\";\n",
       "                var nbb_formatted_code = \"# Evaluate on test set\\nscores = model.evaluate(X_test, y_test)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on test set\n",
    "scores = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 0.0346 - accuracy: 0.9756 - recall_m: 0.9562\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"# Evaluate on training set\\nscores_train = model.evaluate(X_train, y_train)\";\n",
       "                var nbb_formatted_code = \"# Evaluate on training set\\nscores_train = model.evaluate(X_train, y_train)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on training set\n",
    "scores_train = model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 27;\n",
       "                var nbb_unformatted_code = \"# Evaluate the trained model on training set filtered by age, for every 10% percentile of age\\n\\n\\ndef calculate_model_metrics_for_age(model, age_threshold):\\n    age_threshold_filter_lt = X_train[\\\"age\\\"] <= age_threshold\\n    age_threshold_filter_gt = X_train[\\\"age\\\"] > age_threshold\\n\\n    age_threshold_filter_test_lt = X_test[\\\"age\\\"] <= age_threshold\\n    age_threshold_filter_test_gt = X_test[\\\"age\\\"] > age_threshold\\n\\n    # Evaluate the model on the items in the training set BELOW the threshold\\n    lt_metrics_train = model.evaluate(\\n        X_train[age_threshold_filter_lt], y_train[age_threshold_filter_lt], verbose=0\\n    )\\n    gt_metrics_train = model.evaluate(\\n        X_train[age_threshold_filter_gt], y_train[age_threshold_filter_gt], verbose=0\\n    )\\n    # Evaluate the model on the items in the test set BELOW the threshold\\n    lt_metrics_test = model.evaluate(\\n        X_test[age_threshold_filter_test_lt],\\n        y_test[age_threshold_filter_test_lt],\\n        verbose=0,\\n    )\\n    gt_metrics_test = model.evaluate(\\n        X_test[age_threshold_filter_test_gt],\\n        y_test[age_threshold_filter_test_gt],\\n        verbose=0,\\n    )\\n    return (lt_metrics_train, gt_metrics_train, lt_metrics_test, gt_metrics_test)\\n\\n\\ndef evaluate_model_for_age_groups(model):\\n    print(\\\"**** Evaluate model recall for train and test set across age groups ****\\\")\\n    metrics = list()\\n    for age_threshold_percentile in list(np.linspace(0.3, 0.9, 8)):\\n        # for age_threshold_percentile in [0.01, 0.25, 0.5, 0.75, 0.99]:\\n        age_threshold = df[\\\"age\\\"].quantile(age_threshold_percentile)\\n        (\\n            lt_metrics_train,\\n            gt_metrics_train,\\n            lt_metrics_test,\\n            gt_metrics_test,\\n        ) = calculate_model_metrics_for_age(model, age_threshold)\\n        #print(\\n        #    \\\"Age Threshold: {:0.0f} train_recall (LT, GT): {:0.2f},{:0.2f} test_recall (LT, GT): {:0.2f},{:0.2f}\\\".format(\\n        #        age_threshold,\\n        #        lt_metrics_train[2],\\n        #        gt_metrics_train[2],\\n        #        lt_metrics_test[2],\\n        #        gt_metrics_test[2],\\n        #    )\\n        print(\\n            \\\"Age Threshold < {:0.0f}: recall={:0.2f}\\\".format(\\n                age_threshold,\\n                lt_metrics_train[2]\\n            )\\n        )\\n        metrics.append((age_threshold, lt_metrics_train[2]))\\n    return metrics\\n        \";\n",
       "                var nbb_formatted_code = \"# Evaluate the trained model on training set filtered by age, for every 10% percentile of age\\n\\n\\ndef calculate_model_metrics_for_age(model, age_threshold):\\n    age_threshold_filter_lt = X_train[\\\"age\\\"] <= age_threshold\\n    age_threshold_filter_gt = X_train[\\\"age\\\"] > age_threshold\\n\\n    age_threshold_filter_test_lt = X_test[\\\"age\\\"] <= age_threshold\\n    age_threshold_filter_test_gt = X_test[\\\"age\\\"] > age_threshold\\n\\n    # Evaluate the model on the items in the training set BELOW the threshold\\n    lt_metrics_train = model.evaluate(\\n        X_train[age_threshold_filter_lt], y_train[age_threshold_filter_lt], verbose=0\\n    )\\n    gt_metrics_train = model.evaluate(\\n        X_train[age_threshold_filter_gt], y_train[age_threshold_filter_gt], verbose=0\\n    )\\n    # Evaluate the model on the items in the test set BELOW the threshold\\n    lt_metrics_test = model.evaluate(\\n        X_test[age_threshold_filter_test_lt],\\n        y_test[age_threshold_filter_test_lt],\\n        verbose=0,\\n    )\\n    gt_metrics_test = model.evaluate(\\n        X_test[age_threshold_filter_test_gt],\\n        y_test[age_threshold_filter_test_gt],\\n        verbose=0,\\n    )\\n    return (lt_metrics_train, gt_metrics_train, lt_metrics_test, gt_metrics_test)\\n\\n\\ndef evaluate_model_for_age_groups(model):\\n    print(\\\"**** Evaluate model recall for train and test set across age groups ****\\\")\\n    metrics = list()\\n    for age_threshold_percentile in list(np.linspace(0.3, 0.9, 8)):\\n        # for age_threshold_percentile in [0.01, 0.25, 0.5, 0.75, 0.99]:\\n        age_threshold = df[\\\"age\\\"].quantile(age_threshold_percentile)\\n        (\\n            lt_metrics_train,\\n            gt_metrics_train,\\n            lt_metrics_test,\\n            gt_metrics_test,\\n        ) = calculate_model_metrics_for_age(model, age_threshold)\\n        # print(\\n        #    \\\"Age Threshold: {:0.0f} train_recall (LT, GT): {:0.2f},{:0.2f} test_recall (LT, GT): {:0.2f},{:0.2f}\\\".format(\\n        #        age_threshold,\\n        #        lt_metrics_train[2],\\n        #        gt_metrics_train[2],\\n        #        lt_metrics_test[2],\\n        #        gt_metrics_test[2],\\n        #    )\\n        print(\\n            \\\"Age Threshold < {:0.0f}: recall={:0.2f}\\\".format(\\n                age_threshold, lt_metrics_train[2]\\n            )\\n        )\\n        metrics.append((age_threshold, lt_metrics_train[2]))\\n    return metrics\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the trained model on training set filtered by age, for every 10% percentile of age\n",
    "\n",
    "\n",
    "def calculate_model_metrics_for_age(model, age_threshold):\n",
    "    age_threshold_filter_lt = X_train[\"age\"] <= age_threshold\n",
    "    age_threshold_filter_gt = X_train[\"age\"] > age_threshold\n",
    "\n",
    "    age_threshold_filter_test_lt = X_test[\"age\"] <= age_threshold\n",
    "    age_threshold_filter_test_gt = X_test[\"age\"] > age_threshold\n",
    "\n",
    "    # Evaluate the model on the items in the training set BELOW the threshold\n",
    "    lt_metrics_train = model.evaluate(\n",
    "        X_train[age_threshold_filter_lt], y_train[age_threshold_filter_lt], verbose=0\n",
    "    )\n",
    "    gt_metrics_train = model.evaluate(\n",
    "        X_train[age_threshold_filter_gt], y_train[age_threshold_filter_gt], verbose=0\n",
    "    )\n",
    "    # Evaluate the model on the items in the test set BELOW the threshold\n",
    "    lt_metrics_test = model.evaluate(\n",
    "        X_test[age_threshold_filter_test_lt],\n",
    "        y_test[age_threshold_filter_test_lt],\n",
    "        verbose=0,\n",
    "    )\n",
    "    gt_metrics_test = model.evaluate(\n",
    "        X_test[age_threshold_filter_test_gt],\n",
    "        y_test[age_threshold_filter_test_gt],\n",
    "        verbose=0,\n",
    "    )\n",
    "    return (lt_metrics_train, gt_metrics_train, lt_metrics_test, gt_metrics_test)\n",
    "\n",
    "\n",
    "def evaluate_model_for_age_groups(model):\n",
    "    print(\"**** Evaluate model recall for train and test set across age groups ****\")\n",
    "    metrics = list()\n",
    "    for age_threshold_percentile in list(np.linspace(0.3, 0.9, 8)):\n",
    "        # for age_threshold_percentile in [0.01, 0.25, 0.5, 0.75, 0.99]:\n",
    "        age_threshold = df[\"age\"].quantile(age_threshold_percentile)\n",
    "        (\n",
    "            lt_metrics_train,\n",
    "            gt_metrics_train,\n",
    "            lt_metrics_test,\n",
    "            gt_metrics_test,\n",
    "        ) = calculate_model_metrics_for_age(model, age_threshold)\n",
    "        #print(\n",
    "        #    \"Age Threshold: {:0.0f} train_recall (LT, GT): {:0.2f},{:0.2f} test_recall (LT, GT): {:0.2f},{:0.2f}\".format(\n",
    "        #        age_threshold,\n",
    "        #        lt_metrics_train[2],\n",
    "        #        gt_metrics_train[2],\n",
    "        #        lt_metrics_test[2],\n",
    "        #        gt_metrics_test[2],\n",
    "        #    )\n",
    "        print(\n",
    "            \"Age Threshold < {:0.0f}: recall={:0.2f}\".format(\n",
    "                age_threshold,\n",
    "                lt_metrics_train[2]\n",
    "            )\n",
    "        )\n",
    "        metrics.append((age_threshold, lt_metrics_train[2]))\n",
    "    return metrics\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Evaluate model recall for train and test set across age groups ****\n",
      "Age Threshold < 28: recall=0.77\n",
      "Age Threshold < 31: recall=0.88\n",
      "Age Threshold < 35: recall=0.89\n",
      "Age Threshold < 40: recall=0.94\n",
      "Age Threshold < 43: recall=0.94\n",
      "Age Threshold < 45: recall=0.92\n",
      "Age Threshold < 48: recall=0.95\n",
      "Age Threshold < 54: recall=0.95\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"orig_model_metrics = evaluate_model_for_age_groups(model)\";\n",
       "                var nbb_formatted_code = \"orig_model_metrics = evaluate_model_for_age_groups(model)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orig_model_metrics = evaluate_model_for_age_groups(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: its a great model for adults, but performs poorly for non-adults less than 20 years of age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFCO model\n",
    "\n",
    "References:\n",
    "\n",
    "https://www.tensorflow.org/responsible_ai/fairness_indicators/tutorials/Fairness_Indicators_TFCO_CelebA_Case_Study\n",
    "\n",
    "https://github.com/google-research/tensorflow_constrained_optimization/blob/master/examples/jupyter/Fairness_adult.ipynb\n",
    "\n",
    "https://github.com/google-research/tensorflow_constrained_optimization/blob/master/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 29;\n",
       "                var nbb_unformatted_code = \"import tensorflow_constrained_optimization as tfco\";\n",
       "                var nbb_formatted_code = \"import tensorflow_constrained_optimization as tfco\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow_constrained_optimization as tfco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"set_seeds()\";\n",
       "                var nbb_formatted_code = \"set_seeds()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_seeds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eager execution enabled by default.\n",
      "TensorFlow 2.4.0\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"## Enable eager execution\\nif tf.__version__ < \\\"2.0.0\\\":\\n    tf.compat.v1.enable_eager_execution()\\n    print(\\\"Eager execution enabled.\\\")\\nelse:\\n    print(\\\"Eager execution enabled by default.\\\")\\n\\nprint(\\\"TensorFlow \\\" + tf.__version__)\";\n",
       "                var nbb_formatted_code = \"## Enable eager execution\\nif tf.__version__ < \\\"2.0.0\\\":\\n    tf.compat.v1.enable_eager_execution()\\n    print(\\\"Eager execution enabled.\\\")\\nelse:\\n    print(\\\"Eager execution enabled by default.\\\")\\n\\nprint(\\\"TensorFlow \\\" + tf.__version__)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Enable eager execution\n",
    "if tf.__version__ < \"2.0.0\":\n",
    "    tf.compat.v1.enable_eager_execution()\n",
    "    print(\"Eager execution enabled.\")\n",
    "else:\n",
    "    print(\"Eager execution enabled by default.\")\n",
    "\n",
    "print(\"TensorFlow \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"# This is a small data set so train the entire batch at once\\nbatch_size = X_train.shape[0]\\nnum_features = X_train.shape[1]\";\n",
       "                var nbb_formatted_code = \"# This is a small data set so train the entire batch at once\\nbatch_size = X_train.shape[0]\\nnum_features = X_train.shape[1]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This is a small data set so train the entire batch at once\n",
    "batch_size = X_train.shape[0]\n",
    "num_features = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Create a contrained model from the original model\\nmodel_constrained = create_model()\";\n",
       "                var nbb_formatted_code = \"# Create a contrained model from the original model\\nmodel_constrained = create_model()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a contrained model from the original model\n",
    "model_constrained = create_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As documented in TFCO's library, there are several helpers that will make it easier to constrain the problem:\n",
    "\n",
    "1. tfco.rate_context() – This is what will be used in constructing a constraint for each age group category.\n",
    "2. tfco.RateMinimizationProblem()– The rate expression to be minimized here will be the recall rate subject to age group. In other words, performance now will be evaluated based on the difference between the recall rates of the age group and that of the overall dataset. For this demonstration, a recall rate of greater than 80%-95% will be set as the constraint.\n",
    "3. tfco.ProxyLagrangianOptimizerV2() – This is the helper that will actually solve the rate constraint problem.\n",
    "\n",
    "The cell below will call on these helpers to set up model training with the fairness constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"# Create input tensor: TODO -> use len(columns_to_retain) - 1 to create this\\ninput_tensor = tf.Variable(\\n    np.zeros((batch_size, num_features), dtype=\\\"float32\\\"), name=\\\"input\\\"\\n)\";\n",
       "                var nbb_formatted_code = \"# Create input tensor: TODO -> use len(columns_to_retain) - 1 to create this\\ninput_tensor = tf.Variable(\\n    np.zeros((batch_size, num_features), dtype=\\\"float32\\\"), name=\\\"input\\\"\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create input tensor: TODO -> use len(columns_to_retain) - 1 to create this\n",
    "input_tensor = tf.Variable(\n",
    "    np.zeros((batch_size, num_features), dtype=\"float32\"), name=\"input\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 35;\n",
       "                var nbb_unformatted_code = \"# Create labels and group tensors (both are binary)\\nlabels_tensor = tf.Variable(np.zeros(batch_size, dtype=\\\"float32\\\"), name=\\\"labels\\\")\\ngroups_tensor = tf.Variable(np.zeros(batch_size, dtype=\\\"float32\\\"), name=\\\"groups\\\")\";\n",
       "                var nbb_formatted_code = \"# Create labels and group tensors (both are binary)\\nlabels_tensor = tf.Variable(np.zeros(batch_size, dtype=\\\"float32\\\"), name=\\\"labels\\\")\\ngroups_tensor = tf.Variable(np.zeros(batch_size, dtype=\\\"float32\\\"), name=\\\"groups\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create labels and group tensors (both are binary)\n",
    "labels_tensor = tf.Variable(np.zeros(batch_size, dtype=\"float32\"), name=\"labels\")\n",
    "groups_tensor = tf.Variable(np.zeros(batch_size, dtype=\"float32\"), name=\"groups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 36;\n",
       "                var nbb_unformatted_code = \"# Create a function that returns the applied 'model' to the input tensor\\n# and generates constrained predictions.\\ndef predictions():\\n    return model_constrained(input_tensor)\";\n",
       "                var nbb_formatted_code = \"# Create a function that returns the applied 'model' to the input tensor\\n# and generates constrained predictions.\\ndef predictions():\\n    return model_constrained(input_tensor)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a function that returns the applied 'model' to the input tensor\n",
    "# and generates constrained predictions.\n",
    "def predictions():\n",
    "    return model_constrained(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 37;\n",
       "                var nbb_unformatted_code = \"# Create overall context and subsetted context.\\n# The subsetted context contains subset of examples where group attribute > 0\\n# (i.e. the subset of \\\"Young\\\" images).\\n# \\\"groups_tensor > 0\\\" is used instead of \\\"groups_tensor == 1\\\" as the former\\n# would be a comparison on the tensor value, while the latter would be a\\n# comparison on the Tensor object.\\ncontext = tfco.rate_context(predictions, labels=lambda: labels_tensor)\\ncontext_subset = context.subset(lambda: groups_tensor > 0)\";\n",
       "                var nbb_formatted_code = \"# Create overall context and subsetted context.\\n# The subsetted context contains subset of examples where group attribute > 0\\n# (i.e. the subset of \\\"Young\\\" images).\\n# \\\"groups_tensor > 0\\\" is used instead of \\\"groups_tensor == 1\\\" as the former\\n# would be a comparison on the tensor value, while the latter would be a\\n# comparison on the Tensor object.\\ncontext = tfco.rate_context(predictions, labels=lambda: labels_tensor)\\ncontext_subset = context.subset(lambda: groups_tensor > 0)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create overall context and subsetted context.\n",
    "# The subsetted context contains subset of examples where group attribute > 0\n",
    "# (i.e. the subset of \"Young\" images).\n",
    "# \"groups_tensor > 0\" is used instead of \"groups_tensor == 1\" as the former\n",
    "# would be a comparison on the tensor value, while the latter would be a\n",
    "# comparison on the Tensor object.\n",
    "context = tfco.rate_context(predictions, labels=lambda: labels_tensor)\n",
    "context_subset = context.subset(lambda: groups_tensor > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup list of constraints. We will constrain the recall to be at least 90%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 38;\n",
       "                var nbb_unformatted_code = \"# Setup list of constraints.\\n# *We will constrain the recall to be at least 90%*\\nrecall_lower_bound = 0.90\\nconstraints = [tfco.recall(context_subset) >= recall_lower_bound]\";\n",
       "                var nbb_formatted_code = \"# Setup list of constraints.\\n# *We will constrain the recall to be at least 90%*\\nrecall_lower_bound = 0.90\\nconstraints = [tfco.recall(context_subset) >= recall_lower_bound]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup list of constraints.\n",
    "# *We will constrain the recall to be at least 90%*\n",
    "recall_lower_bound = 0.90\n",
    "constraints = [tfco.recall(context_subset) >= recall_lower_bound]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 39;\n",
       "                var nbb_unformatted_code = \"# Setup rate minimization problem: minimize overall error rate s.t. constraints are satisfied.\\nproblem = tfco.RateMinimizationProblem(tfco.error_rate(context), constraints)\";\n",
       "                var nbb_formatted_code = \"# Setup rate minimization problem: minimize overall error rate s.t. constraints are satisfied.\\nproblem = tfco.RateMinimizationProblem(tfco.error_rate(context), constraints)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Setup rate minimization problem: minimize overall error rate s.t. constraints are satisfied.\n",
    "problem = tfco.RateMinimizationProblem(tfco.error_rate(context), constraints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 40;\n",
       "                var nbb_unformatted_code = \"# Create constrained optimizer and obtain train_op.\\n# Separate optimizers are specified for the objective and constraints.\\noptimizer = tfco.ProxyLagrangianOptimizerV2(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    # constraint_optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    constraint_optimizer=tf.keras.optimizers.Adagrad(learning_rate=1),\\n    num_constraints=problem.num_constraints,\\n)\";\n",
       "                var nbb_formatted_code = \"# Create constrained optimizer and obtain train_op.\\n# Separate optimizers are specified for the objective and constraints.\\noptimizer = tfco.ProxyLagrangianOptimizerV2(\\n    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    # constraint_optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\\n    constraint_optimizer=tf.keras.optimizers.Adagrad(learning_rate=1),\\n    num_constraints=problem.num_constraints,\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create constrained optimizer and obtain train_op.\n",
    "# Separate optimizers are specified for the objective and constraints.\n",
    "optimizer = tfco.ProxyLagrangianOptimizerV2(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    # constraint_optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    constraint_optimizer=tf.keras.optimizers.Adagrad(learning_rate=1),\n",
    "    num_constraints=problem.num_constraints,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 41;\n",
       "                var nbb_unformatted_code = \"# A list of all trainable variables is also needed to use TFCO.\\nvar_list = (\\n    model_constrained.trainable_weights\\n    + list(problem.trainable_variables)\\n    + optimizer.trainable_variables()\\n)\";\n",
       "                var nbb_formatted_code = \"# A list of all trainable variables is also needed to use TFCO.\\nvar_list = (\\n    model_constrained.trainable_weights\\n    + list(problem.trainable_variables)\\n    + optimizer.trainable_variables()\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A list of all trainable variables is also needed to use TFCO.\n",
    "var_list = (\n",
    "    model_constrained.trainable_weights\n",
    "    + list(problem.trainable_variables)\n",
    "    + optimizer.trainable_variables()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 42;\n",
       "                var nbb_unformatted_code = \"# Debug info\\n# print(\\\"Model trainable vars: {}\\\".format(model_constrained.trainable_weights))\\n# print(\\\"Problem trainable vars: {}\\\".format(problem.trainable_variables))\\n# print(\\\"Optimizer trainable vars: {}\\\".format(optimizer.trainable_variables()))\";\n",
       "                var nbb_formatted_code = \"# Debug info\\n# print(\\\"Model trainable vars: {}\\\".format(model_constrained.trainable_weights))\\n# print(\\\"Problem trainable vars: {}\\\".format(problem.trainable_variables))\\n# print(\\\"Optimizer trainable vars: {}\\\".format(optimizer.trainable_variables()))\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Debug info\n",
    "# print(\"Model trainable vars: {}\".format(model_constrained.trainable_weights))\n",
    "# print(\"Problem trainable vars: {}\".format(problem.trainable_variables))\n",
    "# print(\"Optimizer trainable vars: {}\".format(optimizer.trainable_variables()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 1: Hinge Loss = 2.288, Max. Constraint Violation = 0.789\n",
      " Iteration 2: Hinge Loss = 2.038, Max. Constraint Violation = 0.789\n",
      " Iteration 3: Hinge Loss = 1.748, Max. Constraint Violation = 0.789\n",
      " Iteration 4: Hinge Loss = 1.430, Max. Constraint Violation = 0.789\n",
      " Iteration 5: Hinge Loss = 1.107, Max. Constraint Violation = 0.789\n",
      " Iteration 6: Hinge Loss = 0.913, Max. Constraint Violation = 0.567\n",
      " Iteration 7: Hinge Loss = 0.882, Max. Constraint Violation = 0.233\n",
      " Iteration 8: Hinge Loss = 0.875, Max. Constraint Violation = -0.100\n",
      " Iteration 9: Hinge Loss = 0.851, Max. Constraint Violation = -0.100\n",
      " Iteration 10: Hinge Loss = 0.791, Max. Constraint Violation = -0.100\n",
      " Iteration 11: Hinge Loss = 0.667, Max. Constraint Violation = 0.011\n",
      " Iteration 12: Hinge Loss = 0.505, Max. Constraint Violation = 0.011\n",
      " Iteration 13: Hinge Loss = 0.359, Max. Constraint Violation = 0.122\n",
      " Iteration 14: Hinge Loss = 0.269, Max. Constraint Violation = 0.344\n",
      " Iteration 15: Hinge Loss = 0.246, Max. Constraint Violation = 0.456\n",
      " Iteration 16: Hinge Loss = 0.262, Max. Constraint Violation = 0.456\n",
      " Iteration 17: Hinge Loss = 0.283, Max. Constraint Violation = 0.456\n",
      " Iteration 18: Hinge Loss = 0.299, Max. Constraint Violation = 0.456\n",
      " Iteration 19: Hinge Loss = 0.299, Max. Constraint Violation = 0.456\n",
      " Iteration 20: Hinge Loss = 0.285, Max. Constraint Violation = 0.456\n",
      " Iteration 21: Hinge Loss = 0.265, Max. Constraint Violation = 0.456\n",
      " Iteration 22: Hinge Loss = 0.246, Max. Constraint Violation = 0.456\n",
      " Iteration 23: Hinge Loss = 0.229, Max. Constraint Violation = 0.456\n",
      " Iteration 24: Hinge Loss = 0.214, Max. Constraint Violation = 0.344\n",
      " Iteration 25: Hinge Loss = 0.204, Max. Constraint Violation = 0.344\n",
      " Iteration 26: Hinge Loss = 0.204, Max. Constraint Violation = 0.233\n",
      " Iteration 27: Hinge Loss = 0.218, Max. Constraint Violation = 0.122\n",
      " Iteration 28: Hinge Loss = 0.251, Max. Constraint Violation = 0.122\n",
      " Iteration 29: Hinge Loss = 0.281, Max. Constraint Violation = 0.122\n",
      " Iteration 30: Hinge Loss = 0.298, Max. Constraint Violation = 0.122\n",
      " Iteration 31: Hinge Loss = 0.296, Max. Constraint Violation = 0.122\n",
      " Iteration 32: Hinge Loss = 0.277, Max. Constraint Violation = 0.122\n",
      " Iteration 33: Hinge Loss = 0.251, Max. Constraint Violation = 0.122\n",
      " Iteration 34: Hinge Loss = 0.224, Max. Constraint Violation = 0.122\n",
      " Iteration 35: Hinge Loss = 0.202, Max. Constraint Violation = 0.122\n",
      " Iteration 36: Hinge Loss = 0.188, Max. Constraint Violation = 0.122\n",
      " Iteration 37: Hinge Loss = 0.181, Max. Constraint Violation = 0.233\n",
      " Iteration 38: Hinge Loss = 0.177, Max. Constraint Violation = 0.233\n",
      " Iteration 39: Hinge Loss = 0.174, Max. Constraint Violation = 0.233\n",
      " Iteration 40: Hinge Loss = 0.172, Max. Constraint Violation = 0.122\n",
      " Iteration 41: Hinge Loss = 0.174, Max. Constraint Violation = 0.122\n",
      " Iteration 42: Hinge Loss = 0.181, Max. Constraint Violation = 0.122\n",
      " Iteration 43: Hinge Loss = 0.194, Max. Constraint Violation = 0.122\n",
      " Iteration 44: Hinge Loss = 0.212, Max. Constraint Violation = 0.122\n",
      " Iteration 45: Hinge Loss = 0.226, Max. Constraint Violation = 0.122\n",
      " Iteration 46: Hinge Loss = 0.235, Max. Constraint Violation = 0.122\n",
      " Iteration 47: Hinge Loss = 0.235, Max. Constraint Violation = 0.122\n",
      " Iteration 48: Hinge Loss = 0.225, Max. Constraint Violation = 0.122\n",
      " Iteration 49: Hinge Loss = 0.210, Max. Constraint Violation = 0.122\n",
      " Iteration 50: Hinge Loss = 0.193, Max. Constraint Violation = 0.122\n",
      " Iteration 51: Hinge Loss = 0.182, Max. Constraint Violation = 0.122\n",
      " Iteration 52: Hinge Loss = 0.175, Max. Constraint Violation = 0.122\n",
      " Iteration 53: Hinge Loss = 0.173, Max. Constraint Violation = 0.122\n",
      " Iteration 54: Hinge Loss = 0.174, Max. Constraint Violation = 0.122\n",
      " Iteration 55: Hinge Loss = 0.180, Max. Constraint Violation = 0.011\n",
      " Iteration 56: Hinge Loss = 0.190, Max. Constraint Violation = 0.011\n",
      " Iteration 57: Hinge Loss = 0.198, Max. Constraint Violation = 0.011\n",
      " Iteration 58: Hinge Loss = 0.199, Max. Constraint Violation = 0.011\n",
      " Iteration 59: Hinge Loss = 0.193, Max. Constraint Violation = 0.011\n",
      " Iteration 60: Hinge Loss = 0.182, Max. Constraint Violation = 0.011\n",
      " Iteration 61: Hinge Loss = 0.170, Max. Constraint Violation = 0.011\n",
      " Iteration 62: Hinge Loss = 0.162, Max. Constraint Violation = 0.011\n",
      " Iteration 63: Hinge Loss = 0.157, Max. Constraint Violation = 0.011\n",
      " Iteration 64: Hinge Loss = 0.157, Max. Constraint Violation = 0.011\n",
      " Iteration 65: Hinge Loss = 0.160, Max. Constraint Violation = 0.011\n",
      " Iteration 66: Hinge Loss = 0.168, Max. Constraint Violation = 0.011\n",
      " Iteration 67: Hinge Loss = 0.177, Max. Constraint Violation = 0.011\n",
      " Iteration 68: Hinge Loss = 0.181, Max. Constraint Violation = 0.011\n",
      " Iteration 69: Hinge Loss = 0.180, Max. Constraint Violation = 0.011\n",
      " Iteration 70: Hinge Loss = 0.175, Max. Constraint Violation = 0.011\n",
      " Iteration 71: Hinge Loss = 0.168, Max. Constraint Violation = 0.011\n",
      " Iteration 72: Hinge Loss = 0.162, Max. Constraint Violation = 0.011\n",
      " Iteration 73: Hinge Loss = 0.159, Max. Constraint Violation = 0.011\n",
      " Iteration 74: Hinge Loss = 0.159, Max. Constraint Violation = 0.011\n",
      " Iteration 75: Hinge Loss = 0.161, Max. Constraint Violation = 0.011\n",
      " Iteration 76: Hinge Loss = 0.163, Max. Constraint Violation = 0.011\n",
      " Iteration 77: Hinge Loss = 0.162, Max. Constraint Violation = 0.011\n",
      " Iteration 78: Hinge Loss = 0.159, Max. Constraint Violation = 0.011\n",
      " Iteration 79: Hinge Loss = 0.155, Max. Constraint Violation = 0.011\n",
      " Iteration 80: Hinge Loss = 0.153, Max. Constraint Violation = 0.011\n",
      " Iteration 81: Hinge Loss = 0.153, Max. Constraint Violation = 0.011\n",
      " Iteration 82: Hinge Loss = 0.154, Max. Constraint Violation = 0.011\n",
      " Iteration 83: Hinge Loss = 0.156, Max. Constraint Violation = 0.011\n",
      " Iteration 84: Hinge Loss = 0.156, Max. Constraint Violation = 0.011\n",
      " Iteration 85: Hinge Loss = 0.154, Max. Constraint Violation = 0.011\n",
      " Iteration 86: Hinge Loss = 0.150, Max. Constraint Violation = 0.011\n",
      " Iteration 87: Hinge Loss = 0.148, Max. Constraint Violation = 0.011\n",
      " Iteration 88: Hinge Loss = 0.147, Max. Constraint Violation = 0.011\n",
      " Iteration 89: Hinge Loss = 0.147, Max. Constraint Violation = 0.011\n",
      " Iteration 90: Hinge Loss = 0.146, Max. Constraint Violation = 0.011\n",
      " Iteration 91: Hinge Loss = 0.145, Max. Constraint Violation = 0.011\n",
      " Iteration 92: Hinge Loss = 0.143, Max. Constraint Violation = 0.011\n",
      " Iteration 93: Hinge Loss = 0.146, Max. Constraint Violation = 0.011\n",
      " Iteration 94: Hinge Loss = 0.146, Max. Constraint Violation = 0.011\n",
      " Iteration 95: Hinge Loss = 0.143, Max. Constraint Violation = 0.011\n",
      " Iteration 96: Hinge Loss = 0.141, Max. Constraint Violation = 0.011\n",
      " Iteration 97: Hinge Loss = 0.141, Max. Constraint Violation = 0.011\n",
      " Iteration 98: Hinge Loss = 0.142, Max. Constraint Violation = 0.011\n",
      " Iteration 99: Hinge Loss = 0.145, Max. Constraint Violation = 0.011\n",
      " Iteration 100: Hinge Loss = 0.143, Max. Constraint Violation = 0.011\n",
      " Iteration 101: Hinge Loss = 0.139, Max. Constraint Violation = 0.011\n",
      " Iteration 102: Hinge Loss = 0.138, Max. Constraint Violation = 0.011\n",
      " Iteration 103: Hinge Loss = 0.138, Max. Constraint Violation = 0.011\n",
      " Iteration 104: Hinge Loss = 0.137, Max. Constraint Violation = 0.011\n",
      " Iteration 105: Hinge Loss = 0.135, Max. Constraint Violation = 0.011\n",
      " Iteration 106: Hinge Loss = 0.134, Max. Constraint Violation = 0.011\n",
      " Iteration 107: Hinge Loss = 0.132, Max. Constraint Violation = 0.011\n",
      " Iteration 108: Hinge Loss = 0.129, Max. Constraint Violation = 0.011\n",
      " Iteration 109: Hinge Loss = 0.128, Max. Constraint Violation = 0.011\n",
      " Iteration 110: Hinge Loss = 0.131, Max. Constraint Violation = 0.011\n",
      " Iteration 111: Hinge Loss = 0.128, Max. Constraint Violation = 0.011\n",
      " Iteration 112: Hinge Loss = 0.123, Max. Constraint Violation = 0.011\n",
      " Iteration 113: Hinge Loss = 0.123, Max. Constraint Violation = 0.011\n",
      " Iteration 114: Hinge Loss = 0.130, Max. Constraint Violation = 0.011\n",
      " Iteration 115: Hinge Loss = 0.132, Max. Constraint Violation = 0.011\n",
      " Iteration 116: Hinge Loss = 0.129, Max. Constraint Violation = 0.011\n",
      " Iteration 117: Hinge Loss = 0.121, Max. Constraint Violation = 0.011\n",
      " Iteration 118: Hinge Loss = 0.116, Max. Constraint Violation = 0.011\n",
      " Iteration 119: Hinge Loss = 0.116, Max. Constraint Violation = 0.011\n",
      " Iteration 120: Hinge Loss = 0.120, Max. Constraint Violation = 0.011\n",
      " Iteration 121: Hinge Loss = 0.123, Max. Constraint Violation = 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 122: Hinge Loss = 0.124, Max. Constraint Violation = 0.011\n",
      " Iteration 123: Hinge Loss = 0.122, Max. Constraint Violation = 0.011\n",
      " Iteration 124: Hinge Loss = 0.117, Max. Constraint Violation = 0.011\n",
      " Iteration 125: Hinge Loss = 0.114, Max. Constraint Violation = 0.011\n",
      " Iteration 126: Hinge Loss = 0.114, Max. Constraint Violation = 0.011\n",
      " Iteration 127: Hinge Loss = 0.117, Max. Constraint Violation = 0.011\n",
      " Iteration 128: Hinge Loss = 0.119, Max. Constraint Violation = 0.011\n",
      " Iteration 129: Hinge Loss = 0.117, Max. Constraint Violation = 0.011\n",
      " Iteration 130: Hinge Loss = 0.114, Max. Constraint Violation = 0.011\n",
      " Iteration 131: Hinge Loss = 0.112, Max. Constraint Violation = 0.011\n",
      " Iteration 132: Hinge Loss = 0.111, Max. Constraint Violation = 0.011\n",
      " Iteration 133: Hinge Loss = 0.111, Max. Constraint Violation = 0.011\n",
      " Iteration 134: Hinge Loss = 0.113, Max. Constraint Violation = 0.011\n",
      " Iteration 135: Hinge Loss = 0.113, Max. Constraint Violation = 0.011\n",
      " Iteration 136: Hinge Loss = 0.111, Max. Constraint Violation = 0.011\n",
      " Iteration 137: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 138: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 139: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 140: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 141: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 142: Hinge Loss = 0.107, Max. Constraint Violation = 0.011\n",
      " Iteration 143: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 144: Hinge Loss = 0.110, Max. Constraint Violation = 0.011\n",
      " Iteration 145: Hinge Loss = 0.110, Max. Constraint Violation = 0.011\n",
      " Iteration 146: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 147: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 148: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 149: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 150: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 151: Hinge Loss = 0.106, Max. Constraint Violation = 0.011\n",
      " Iteration 152: Hinge Loss = 0.103, Max. Constraint Violation = 0.011\n",
      " Iteration 153: Hinge Loss = 0.104, Max. Constraint Violation = 0.011\n",
      " Iteration 154: Hinge Loss = 0.108, Max. Constraint Violation = 0.011\n",
      " Iteration 155: Hinge Loss = 0.110, Max. Constraint Violation = 0.011\n",
      " Iteration 156: Hinge Loss = 0.110, Max. Constraint Violation = 0.011\n",
      " Iteration 157: Hinge Loss = 0.109, Max. Constraint Violation = 0.011\n",
      " Iteration 158: Hinge Loss = 0.105, Max. Constraint Violation = 0.011\n",
      " Iteration 159: Hinge Loss = 0.102, Max. Constraint Violation = 0.011\n",
      " Iteration 160: Hinge Loss = 0.100, Max. Constraint Violation = 0.011\n",
      " Iteration 161: Hinge Loss = 0.101, Max. Constraint Violation = 0.011\n",
      " Iteration 162: Hinge Loss = 0.104, Max. Constraint Violation = 0.011\n",
      " Iteration 163: Hinge Loss = 0.106, Max. Constraint Violation = 0.011\n",
      " Iteration 164: Hinge Loss = 0.106, Max. Constraint Violation = 0.011\n",
      " Iteration 165: Hinge Loss = 0.104, Max. Constraint Violation = 0.011\n",
      " Iteration 166: Hinge Loss = 0.101, Max. Constraint Violation = 0.011\n",
      " Iteration 167: Hinge Loss = 0.098, Max. Constraint Violation = 0.011\n",
      " Iteration 168: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 169: Hinge Loss = 0.100, Max. Constraint Violation = 0.011\n",
      " Iteration 170: Hinge Loss = 0.102, Max. Constraint Violation = 0.011\n",
      " Iteration 171: Hinge Loss = 0.102, Max. Constraint Violation = 0.011\n",
      " Iteration 172: Hinge Loss = 0.102, Max. Constraint Violation = 0.011\n",
      " Iteration 173: Hinge Loss = 0.101, Max. Constraint Violation = 0.011\n",
      " Iteration 174: Hinge Loss = 0.100, Max. Constraint Violation = 0.011\n",
      " Iteration 175: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 176: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 177: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 178: Hinge Loss = 0.098, Max. Constraint Violation = 0.011\n",
      " Iteration 179: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 180: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 181: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 182: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 183: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 184: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 185: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 186: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 187: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 188: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 189: Hinge Loss = 0.098, Max. Constraint Violation = 0.011\n",
      " Iteration 190: Hinge Loss = 0.099, Max. Constraint Violation = 0.011\n",
      " Iteration 191: Hinge Loss = 0.099, Max. Constraint Violation = 0.011\n",
      " Iteration 192: Hinge Loss = 0.098, Max. Constraint Violation = 0.011\n",
      " Iteration 193: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 194: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 195: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 196: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 197: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 198: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 199: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 200: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 201: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 202: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 203: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 204: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 205: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 206: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 207: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 208: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 209: Hinge Loss = 0.091, Max. Constraint Violation = 0.011\n",
      " Iteration 210: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 211: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 212: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 213: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 214: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 215: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 216: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 217: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 218: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 219: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 220: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 221: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 222: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 223: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 224: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 225: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 226: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 227: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 228: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 229: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 230: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 231: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 232: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 233: Hinge Loss = 0.095, Max. Constraint Violation = 0.011\n",
      " Iteration 234: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 235: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 236: Hinge Loss = 0.094, Max. Constraint Violation = 0.011\n",
      " Iteration 237: Hinge Loss = 0.097, Max. Constraint Violation = 0.011\n",
      " Iteration 238: Hinge Loss = 0.100, Max. Constraint Violation = -0.100\n",
      " Iteration 239: Hinge Loss = 0.100, Max. Constraint Violation = -0.100\n",
      " Iteration 240: Hinge Loss = 0.099, Max. Constraint Violation = -0.100\n",
      " Iteration 241: Hinge Loss = 0.096, Max. Constraint Violation = 0.011\n",
      " Iteration 242: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 243: Hinge Loss = 0.091, Max. Constraint Violation = 0.011\n",
      " Iteration 244: Hinge Loss = 0.089, Max. Constraint Violation = 0.011\n",
      " Iteration 245: Hinge Loss = 0.090, Max. Constraint Violation = 0.011\n",
      " Iteration 246: Hinge Loss = 0.093, Max. Constraint Violation = 0.011\n",
      " Iteration 247: Hinge Loss = 0.097, Max. Constraint Violation = -0.100\n",
      " Iteration 248: Hinge Loss = 0.099, Max. Constraint Violation = -0.100\n",
      " Iteration 249: Hinge Loss = 0.100, Max. Constraint Violation = -0.100\n",
      " Iteration 250: Hinge Loss = 0.098, Max. Constraint Violation = -0.100\n",
      " Iteration 251: Hinge Loss = 0.095, Max. Constraint Violation = -0.100\n",
      " Iteration 252: Hinge Loss = 0.091, Max. Constraint Violation = 0.011\n",
      " Iteration 253: Hinge Loss = 0.089, Max. Constraint Violation = 0.011\n",
      " Iteration 254: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 255: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 256: Hinge Loss = 0.089, Max. Constraint Violation = 0.011\n",
      " Iteration 257: Hinge Loss = 0.091, Max. Constraint Violation = 0.011\n",
      " Iteration 258: Hinge Loss = 0.093, Max. Constraint Violation = -0.100\n",
      " Iteration 259: Hinge Loss = 0.094, Max. Constraint Violation = -0.100\n",
      " Iteration 260: Hinge Loss = 0.094, Max. Constraint Violation = -0.100\n",
      " Iteration 261: Hinge Loss = 0.093, Max. Constraint Violation = -0.100\n",
      " Iteration 262: Hinge Loss = 0.091, Max. Constraint Violation = 0.011\n",
      " Iteration 263: Hinge Loss = 0.088, Max. Constraint Violation = 0.011\n",
      " Iteration 264: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 265: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 266: Hinge Loss = 0.089, Max. Constraint Violation = 0.011\n",
      " Iteration 267: Hinge Loss = 0.091, Max. Constraint Violation = -0.100\n",
      " Iteration 268: Hinge Loss = 0.091, Max. Constraint Violation = -0.100\n",
      " Iteration 269: Hinge Loss = 0.091, Max. Constraint Violation = -0.100\n",
      " Iteration 270: Hinge Loss = 0.090, Max. Constraint Violation = -0.100\n",
      " Iteration 271: Hinge Loss = 0.089, Max. Constraint Violation = -0.100\n",
      " Iteration 272: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 273: Hinge Loss = 0.085, Max. Constraint Violation = 0.011\n",
      " Iteration 274: Hinge Loss = 0.084, Max. Constraint Violation = 0.011\n",
      " Iteration 275: Hinge Loss = 0.085, Max. Constraint Violation = 0.011\n",
      " Iteration 276: Hinge Loss = 0.086, Max. Constraint Violation = 0.011\n",
      " Iteration 277: Hinge Loss = 0.087, Max. Constraint Violation = 0.011\n",
      " Iteration 278: Hinge Loss = 0.086, Max. Constraint Violation = -0.100\n",
      " Iteration 279: Hinge Loss = 0.085, Max. Constraint Violation = 0.011\n",
      " Iteration 280: Hinge Loss = 0.084, Max. Constraint Violation = 0.011\n",
      " Iteration 281: Hinge Loss = 0.082, Max. Constraint Violation = 0.011\n",
      " Iteration 282: Hinge Loss = 0.083, Max. Constraint Violation = 0.011\n",
      " Iteration 283: Hinge Loss = 0.083, Max. Constraint Violation = 0.011\n",
      " Iteration 284: Hinge Loss = 0.083, Max. Constraint Violation = 0.011\n",
      " Iteration 285: Hinge Loss = 0.082, Max. Constraint Violation = 0.011\n",
      " Iteration 286: Hinge Loss = 0.081, Max. Constraint Violation = 0.011\n",
      " Iteration 287: Hinge Loss = 0.082, Max. Constraint Violation = 0.011\n",
      " Iteration 288: Hinge Loss = 0.083, Max. Constraint Violation = -0.100\n",
      " Iteration 289: Hinge Loss = 0.083, Max. Constraint Violation = -0.100\n",
      " Iteration 290: Hinge Loss = 0.082, Max. Constraint Violation = 0.011\n",
      " Iteration 291: Hinge Loss = 0.080, Max. Constraint Violation = 0.011\n",
      " Iteration 292: Hinge Loss = 0.078, Max. Constraint Violation = 0.011\n",
      " Iteration 293: Hinge Loss = 0.079, Max. Constraint Violation = 0.011\n",
      " Iteration 294: Hinge Loss = 0.079, Max. Constraint Violation = 0.011\n",
      " Iteration 295: Hinge Loss = 0.078, Max. Constraint Violation = 0.011\n",
      " Iteration 296: Hinge Loss = 0.077, Max. Constraint Violation = 0.011\n",
      " Iteration 297: Hinge Loss = 0.076, Max. Constraint Violation = 0.011\n",
      " Iteration 298: Hinge Loss = 0.075, Max. Constraint Violation = 0.011\n",
      " Iteration 299: Hinge Loss = 0.076, Max. Constraint Violation = 0.011\n",
      " Iteration 300: Hinge Loss = 0.076, Max. Constraint Violation = 0.011\n",
      " Iteration 301: Hinge Loss = 0.077, Max. Constraint Violation = 0.011\n",
      " Iteration 302: Hinge Loss = 0.076, Max. Constraint Violation = 0.011\n",
      " Iteration 303: Hinge Loss = 0.074, Max. Constraint Violation = 0.011\n",
      " Iteration 304: Hinge Loss = 0.073, Max. Constraint Violation = 0.011\n",
      " Iteration 305: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 306: Hinge Loss = 0.073, Max. Constraint Violation = 0.011\n",
      " Iteration 307: Hinge Loss = 0.074, Max. Constraint Violation = 0.011\n",
      " Iteration 308: Hinge Loss = 0.074, Max. Constraint Violation = 0.011\n",
      " Iteration 309: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 310: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 311: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 312: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 313: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 314: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 315: Hinge Loss = 0.071, Max. Constraint Violation = 0.011\n",
      " Iteration 316: Hinge Loss = 0.069, Max. Constraint Violation = 0.011\n",
      " Iteration 317: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 318: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 319: Hinge Loss = 0.073, Max. Constraint Violation = 0.011\n",
      " Iteration 320: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 321: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 322: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 323: Hinge Loss = 0.067, Max. Constraint Violation = 0.011\n",
      " Iteration 324: Hinge Loss = 0.067, Max. Constraint Violation = 0.011\n",
      " Iteration 325: Hinge Loss = 0.067, Max. Constraint Violation = 0.011\n",
      " Iteration 326: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 327: Hinge Loss = 0.069, Max. Constraint Violation = 0.011\n",
      " Iteration 328: Hinge Loss = 0.071, Max. Constraint Violation = 0.011\n",
      " Iteration 329: Hinge Loss = 0.072, Max. Constraint Violation = 0.011\n",
      " Iteration 330: Hinge Loss = 0.071, Max. Constraint Violation = 0.011\n",
      " Iteration 331: Hinge Loss = 0.069, Max. Constraint Violation = 0.011\n",
      " Iteration 332: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 333: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 334: Hinge Loss = 0.070, Max. Constraint Violation = 0.011\n",
      " Iteration 335: Hinge Loss = 0.071, Max. Constraint Violation = 0.011\n",
      " Iteration 336: Hinge Loss = 0.069, Max. Constraint Violation = 0.011\n",
      " Iteration 337: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 338: Hinge Loss = 0.066, Max. Constraint Violation = 0.011\n",
      " Iteration 339: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n",
      " Iteration 340: Hinge Loss = 0.064, Max. Constraint Violation = 0.011\n",
      " Iteration 341: Hinge Loss = 0.064, Max. Constraint Violation = 0.011\n",
      " Iteration 342: Hinge Loss = 0.066, Max. Constraint Violation = 0.011\n",
      " Iteration 343: Hinge Loss = 0.068, Max. Constraint Violation = 0.011\n",
      " Iteration 344: Hinge Loss = 0.070, Max. Constraint Violation = -0.100\n",
      " Iteration 345: Hinge Loss = 0.071, Max. Constraint Violation = -0.100\n",
      " Iteration 346: Hinge Loss = 0.069, Max. Constraint Violation = -0.100\n",
      " Iteration 347: Hinge Loss = 0.067, Max. Constraint Violation = 0.011\n",
      " Iteration 348: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n",
      " Iteration 349: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n",
      " Iteration 350: Hinge Loss = 0.067, Max. Constraint Violation = -0.100\n",
      " Iteration 351: Hinge Loss = 0.068, Max. Constraint Violation = -0.100\n",
      " Iteration 352: Hinge Loss = 0.068, Max. Constraint Violation = -0.100\n",
      " Iteration 353: Hinge Loss = 0.066, Max. Constraint Violation = 0.011\n",
      " Iteration 354: Hinge Loss = 0.064, Max. Constraint Violation = 0.011\n",
      " Iteration 355: Hinge Loss = 0.062, Max. Constraint Violation = 0.011\n",
      " Iteration 356: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 357: Hinge Loss = 0.062, Max. Constraint Violation = 0.011\n",
      " Iteration 358: Hinge Loss = 0.064, Max. Constraint Violation = 0.011\n",
      " Iteration 359: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 360: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n",
      " Iteration 361: Hinge Loss = 0.065, Max. Constraint Violation = 0.011\n",
      " Iteration 362: Hinge Loss = 0.064, Max. Constraint Violation = 0.011\n",
      " Iteration 363: Hinge Loss = 0.062, Max. Constraint Violation = 0.011\n",
      " Iteration 364: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 365: Hinge Loss = 0.062, Max. Constraint Violation = 0.011\n",
      " Iteration 366: Hinge Loss = 0.063, Max. Constraint Violation = 0.011\n",
      " Iteration 367: Hinge Loss = 0.065, Max. Constraint Violation = -0.100\n",
      " Iteration 368: Hinge Loss = 0.065, Max. Constraint Violation = -0.100\n",
      " Iteration 369: Hinge Loss = 0.064, Max. Constraint Violation = -0.100\n",
      " Iteration 370: Hinge Loss = 0.063, Max. Constraint Violation = 0.011\n",
      " Iteration 371: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 372: Hinge Loss = 0.059, Max. Constraint Violation = 0.011\n",
      " Iteration 373: Hinge Loss = 0.059, Max. Constraint Violation = 0.011\n",
      " Iteration 374: Hinge Loss = 0.060, Max. Constraint Violation = 0.011\n",
      " Iteration 375: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 376: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 377: Hinge Loss = 0.061, Max. Constraint Violation = 0.011\n",
      " Iteration 378: Hinge Loss = 0.060, Max. Constraint Violation = 0.011\n",
      " Iteration 379: Hinge Loss = 0.060, Max. Constraint Violation = 0.011\n",
      " Iteration 380: Hinge Loss = 0.062, Max. Constraint Violation = -0.100\n",
      " Iteration 381: Hinge Loss = 0.062, Max. Constraint Violation = -0.100\n",
      " Iteration 382: Hinge Loss = 0.061, Max. Constraint Violation = -0.100\n",
      " Iteration 383: Hinge Loss = 0.059, Max. Constraint Violation = 0.011\n",
      " Iteration 384: Hinge Loss = 0.058, Max. Constraint Violation = 0.011\n",
      " Iteration 385: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 386: Hinge Loss = 0.058, Max. Constraint Violation = 0.011\n",
      " Iteration 387: Hinge Loss = 0.060, Max. Constraint Violation = -0.100\n",
      " Iteration 388: Hinge Loss = 0.061, Max. Constraint Violation = -0.100\n",
      " Iteration 389: Hinge Loss = 0.060, Max. Constraint Violation = -0.100\n",
      " Iteration 390: Hinge Loss = 0.059, Max. Constraint Violation = -0.100\n",
      " Iteration 391: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 392: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 393: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 394: Hinge Loss = 0.058, Max. Constraint Violation = -0.100\n",
      " Iteration 395: Hinge Loss = 0.059, Max. Constraint Violation = -0.100\n",
      " Iteration 396: Hinge Loss = 0.058, Max. Constraint Violation = -0.100\n",
      " Iteration 397: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 398: Hinge Loss = 0.057, Max. Constraint Violation = 0.011\n",
      " Iteration 399: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 400: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 401: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 402: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 403: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 404: Hinge Loss = 0.055, Max. Constraint Violation = 0.011\n",
      " Iteration 405: Hinge Loss = 0.056, Max. Constraint Violation = -0.100\n",
      " Iteration 406: Hinge Loss = 0.056, Max. Constraint Violation = 0.011\n",
      " Iteration 407: Hinge Loss = 0.055, Max. Constraint Violation = 0.011\n",
      " Iteration 408: Hinge Loss = 0.054, Max. Constraint Violation = 0.011\n",
      " Iteration 409: Hinge Loss = 0.054, Max. Constraint Violation = 0.011\n",
      " Iteration 410: Hinge Loss = 0.054, Max. Constraint Violation = 0.011\n",
      " Iteration 411: Hinge Loss = 0.054, Max. Constraint Violation = 0.011\n",
      " Iteration 412: Hinge Loss = 0.054, Max. Constraint Violation = 0.011\n",
      " Iteration 413: Hinge Loss = 0.056, Max. Constraint Violation = -0.100\n",
      " Iteration 414: Hinge Loss = 0.057, Max. Constraint Violation = -0.100\n",
      " Iteration 415: Hinge Loss = 0.056, Max. Constraint Violation = -0.100\n",
      " Iteration 416: Hinge Loss = 0.055, Max. Constraint Violation = -0.100\n",
      " Iteration 417: Hinge Loss = 0.053, Max. Constraint Violation = 0.011\n",
      " Iteration 418: Hinge Loss = 0.052, Max. Constraint Violation = 0.011\n",
      " Iteration 419: Hinge Loss = 0.053, Max. Constraint Violation = 0.011\n",
      " Iteration 420: Hinge Loss = 0.053, Max. Constraint Violation = 0.011\n",
      " Iteration 421: Hinge Loss = 0.054, Max. Constraint Violation = -0.100\n",
      " Iteration 422: Hinge Loss = 0.054, Max. Constraint Violation = -0.100\n",
      " Iteration 423: Hinge Loss = 0.053, Max. Constraint Violation = -0.100\n",
      " Iteration 424: Hinge Loss = 0.052, Max. Constraint Violation = 0.011\n",
      " Iteration 425: Hinge Loss = 0.052, Max. Constraint Violation = 0.011\n",
      " Iteration 426: Hinge Loss = 0.052, Max. Constraint Violation = 0.011\n",
      " Iteration 427: Hinge Loss = 0.052, Max. Constraint Violation = 0.011\n",
      " Iteration 428: Hinge Loss = 0.053, Max. Constraint Violation = -0.100\n",
      " Iteration 429: Hinge Loss = 0.054, Max. Constraint Violation = -0.100\n",
      " Iteration 430: Hinge Loss = 0.054, Max. Constraint Violation = -0.100\n",
      " Iteration 431: Hinge Loss = 0.052, Max. Constraint Violation = -0.100\n",
      " Iteration 432: Hinge Loss = 0.051, Max. Constraint Violation = 0.011\n",
      " Iteration 433: Hinge Loss = 0.051, Max. Constraint Violation = 0.011\n",
      " Iteration 434: Hinge Loss = 0.051, Max. Constraint Violation = 0.011\n",
      " Iteration 435: Hinge Loss = 0.051, Max. Constraint Violation = -0.100\n",
      " Iteration 436: Hinge Loss = 0.051, Max. Constraint Violation = -0.100\n",
      " Iteration 437: Hinge Loss = 0.051, Max. Constraint Violation = 0.011\n",
      " Iteration 438: Hinge Loss = 0.050, Max. Constraint Violation = 0.011\n",
      " Iteration 439: Hinge Loss = 0.050, Max. Constraint Violation = 0.011\n",
      " Iteration 440: Hinge Loss = 0.050, Max. Constraint Violation = 0.011\n",
      " Iteration 441: Hinge Loss = 0.050, Max. Constraint Violation = 0.011\n",
      " Iteration 442: Hinge Loss = 0.051, Max. Constraint Violation = -0.100\n",
      " Iteration 443: Hinge Loss = 0.051, Max. Constraint Violation = -0.100\n",
      " Iteration 444: Hinge Loss = 0.051, Max. Constraint Violation = -0.100\n",
      " Iteration 445: Hinge Loss = 0.050, Max. Constraint Violation = 0.011\n",
      " Iteration 446: Hinge Loss = 0.049, Max. Constraint Violation = 0.011\n",
      " Iteration 447: Hinge Loss = 0.049, Max. Constraint Violation = 0.011\n",
      " Iteration 448: Hinge Loss = 0.049, Max. Constraint Violation = 0.011\n",
      " Iteration 449: Hinge Loss = 0.049, Max. Constraint Violation = 0.011\n",
      " Iteration 450: Hinge Loss = 0.049, Max. Constraint Violation = 0.011\n",
      " Iteration 451: Hinge Loss = 0.048, Max. Constraint Violation = 0.011\n",
      " Iteration 452: Hinge Loss = 0.048, Max. Constraint Violation = 0.011\n",
      " Iteration 453: Hinge Loss = 0.048, Max. Constraint Violation = 0.011\n",
      " Iteration 454: Hinge Loss = 0.048, Max. Constraint Violation = 0.011\n",
      " Iteration 455: Hinge Loss = 0.048, Max. Constraint Violation = -0.100\n",
      " Iteration 456: Hinge Loss = 0.048, Max. Constraint Violation = -0.100\n",
      " Iteration 457: Hinge Loss = 0.048, Max. Constraint Violation = 0.011\n",
      " Iteration 458: Hinge Loss = 0.049, Max. Constraint Violation = -0.100\n",
      " Iteration 459: Hinge Loss = 0.049, Max. Constraint Violation = -0.100\n",
      " Iteration 460: Hinge Loss = 0.048, Max. Constraint Violation = -0.100\n",
      " Iteration 461: Hinge Loss = 0.047, Max. Constraint Violation = 0.011\n",
      " Iteration 462: Hinge Loss = 0.046, Max. Constraint Violation = 0.011\n",
      " Iteration 463: Hinge Loss = 0.046, Max. Constraint Violation = 0.011\n",
      " Iteration 464: Hinge Loss = 0.046, Max. Constraint Violation = 0.011\n",
      " Iteration 465: Hinge Loss = 0.047, Max. Constraint Violation = 0.011\n",
      " Iteration 466: Hinge Loss = 0.047, Max. Constraint Violation = -0.100\n",
      " Iteration 467: Hinge Loss = 0.048, Max. Constraint Violation = -0.100\n",
      " Iteration 468: Hinge Loss = 0.047, Max. Constraint Violation = -0.100\n",
      " Iteration 469: Hinge Loss = 0.046, Max. Constraint Violation = 0.011\n",
      " Iteration 470: Hinge Loss = 0.046, Max. Constraint Violation = 0.011\n",
      " Iteration 471: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 472: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 473: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 474: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 475: Hinge Loss = 0.046, Max. Constraint Violation = -0.100\n",
      " Iteration 476: Hinge Loss = 0.046, Max. Constraint Violation = -0.100\n",
      " Iteration 477: Hinge Loss = 0.046, Max. Constraint Violation = -0.100\n",
      " Iteration 478: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 479: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Iteration 480: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n",
      " Iteration 481: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 482: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n",
      " Iteration 483: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n",
      " Iteration 484: Hinge Loss = 0.045, Max. Constraint Violation = 0.011\n",
      " Iteration 485: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n",
      " Iteration 486: Hinge Loss = 0.044, Max. Constraint Violation = 0.011\n",
      " Iteration 487: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 488: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 489: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 490: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 491: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 492: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 493: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 494: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 495: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 496: Hinge Loss = 0.043, Max. Constraint Violation = -0.100\n",
      " Iteration 497: Hinge Loss = 0.043, Max. Constraint Violation = 0.011\n",
      " Iteration 498: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 499: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n",
      " Iteration 500: Hinge Loss = 0.042, Max. Constraint Violation = 0.011\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 43;\n",
       "                var nbb_unformatted_code = \"# List of objective and constraints across iterations.\\nobjective_list = []\\nviolations_list = []\\n\\n# Assign batch to input, labels and group tensors\\n# Since we are training the full batch, this assignment is outside the loop.\\n# If we need mini-batch, this would be inside the loop.\\ninput_tensor.assign(X_train)\\nlabels_tensor.assign(y_train)\\ngroups_tensor.assign(group_train)\\n\\n# Training iterations.\\niteration_count = 0\\nfor iteration_count in range(n_epochs):\\n    # Run gradient update\\n    optimizer.minimize(problem, var_list=var_list)\\n\\n    #   # Record objective and violations.\\n    objective = problem.objective()\\n    violations = problem.constraints()\\n\\n    print(\\n        \\\"\\\\r Iteration %d: Hinge Loss = %.3f, Max. Constraint Violation = %.3f\\\"\\n        % (iteration_count + 1, objective, max(violations))\\n    )\";\n",
       "                var nbb_formatted_code = \"# List of objective and constraints across iterations.\\nobjective_list = []\\nviolations_list = []\\n\\n# Assign batch to input, labels and group tensors\\n# Since we are training the full batch, this assignment is outside the loop.\\n# If we need mini-batch, this would be inside the loop.\\ninput_tensor.assign(X_train)\\nlabels_tensor.assign(y_train)\\ngroups_tensor.assign(group_train)\\n\\n# Training iterations.\\niteration_count = 0\\nfor iteration_count in range(n_epochs):\\n    # Run gradient update\\n    optimizer.minimize(problem, var_list=var_list)\\n\\n    #   # Record objective and violations.\\n    objective = problem.objective()\\n    violations = problem.constraints()\\n\\n    print(\\n        \\\"\\\\r Iteration %d: Hinge Loss = %.3f, Max. Constraint Violation = %.3f\\\"\\n        % (iteration_count + 1, objective, max(violations))\\n    )\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# List of objective and constraints across iterations.\n",
    "objective_list = []\n",
    "violations_list = []\n",
    "\n",
    "# Assign batch to input, labels and group tensors\n",
    "# Since we are training the full batch, this assignment is outside the loop.\n",
    "# If we need mini-batch, this would be inside the loop.\n",
    "input_tensor.assign(X_train)\n",
    "labels_tensor.assign(y_train)\n",
    "groups_tensor.assign(group_train)\n",
    "\n",
    "# Training iterations.\n",
    "iteration_count = 0\n",
    "for iteration_count in range(n_epochs):\n",
    "    # Run gradient update\n",
    "    optimizer.minimize(problem, var_list=var_list)\n",
    "\n",
    "    #   # Record objective and violations.\n",
    "    objective = problem.objective()\n",
    "    violations = problem.constraints()\n",
    "\n",
    "    print(\n",
    "        \"\\r Iteration %d: Hinge Loss = %.3f, Max. Constraint Violation = %.3f\"\n",
    "        % (iteration_count + 1, objective, max(violations))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Evaluate model recall for train and test set across age groups ****\n",
      "Age Threshold < 28: recall=0.77\n",
      "Age Threshold < 31: recall=0.88\n",
      "Age Threshold < 35: recall=0.89\n",
      "Age Threshold < 40: recall=0.94\n",
      "Age Threshold < 43: recall=0.94\n",
      "Age Threshold < 45: recall=0.92\n",
      "Age Threshold < 48: recall=0.95\n",
      "Age Threshold < 54: recall=0.95\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 44;\n",
       "                var nbb_unformatted_code = \"# Original model\\norig_model_metrics = evaluate_model_for_age_groups(model)\";\n",
       "                var nbb_formatted_code = \"# Original model\\norig_model_metrics = evaluate_model_for_age_groups(model)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Original model\n",
    "orig_model_metrics = evaluate_model_for_age_groups(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Evaluate model recall for train and test set across age groups ****\n",
      "Age Threshold < 28: recall=0.90\n",
      "Age Threshold < 31: recall=0.92\n",
      "Age Threshold < 35: recall=0.93\n",
      "Age Threshold < 40: recall=0.96\n",
      "Age Threshold < 43: recall=0.95\n",
      "Age Threshold < 45: recall=0.94\n",
      "Age Threshold < 48: recall=0.96\n",
      "Age Threshold < 54: recall=0.96\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 45;\n",
       "                var nbb_unformatted_code = \"# New model\\nnew_model_metrics = evaluate_model_for_age_groups(model_constrained)\";\n",
       "                var nbb_formatted_code = \"# New model\\nnew_model_metrics = evaluate_model_for_age_groups(model_constrained)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# New model\n",
    "new_model_metrics = evaluate_model_for_age_groups(model_constrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(28.0, 0.8999999761581421),\n",
       " (31.0, 0.9153439402580261),\n",
       " (35.3142857142857, 0.925000011920929),\n",
       " (40.0, 0.9615384340286255),\n",
       " (43.0, 0.9545454382896423),\n",
       " (45.485714285714295, 0.9375),\n",
       " (48.0, 0.9589285850524902),\n",
       " (54.0, 0.9644444584846497)]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 46;\n",
       "                var nbb_unformatted_code = \"new_model_metrics\";\n",
       "                var nbb_formatted_code = \"new_model_metrics\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 47;\n",
       "                var nbb_unformatted_code = \"def plot_age_recall_barplot(model_metrics, title=\\\"barplot\\\", color=\\\"blue\\\"):\\n    plt.bar(range(len(model_metrics)), [val[1] for val in model_metrics], color=color)\\n    plt.xticks(range(len(model_metrics)), [int(val[0]) for val in model_metrics])\\n    plt.xticks(rotation=70)\\n    plt.title(title)\\n    plt.show()\\n\\n\\nplot_age_recall_barplot(orig_model_metrics, \\\"Unconstrained model\\\", \\\"orange\\\")\\nplot_age_recall_barplot(\\n    new_model_metrics,\\n    \\\"Constrained model with proxy Lagrangian recall constraints using TFCO\\\",\\n    \\\"blue\\\",\\n)\";\n",
       "                var nbb_formatted_code = \"def plot_age_recall_barplot(model_metrics, title=\\\"barplot\\\", color=\\\"blue\\\"):\\n    plt.bar(range(len(model_metrics)), [val[1] for val in model_metrics], color=color)\\n    plt.xticks(range(len(model_metrics)), [int(val[0]) for val in model_metrics])\\n    plt.xticks(rotation=70)\\n    plt.title(title)\\n    plt.show()\\n\\n\\nplot_age_recall_barplot(orig_model_metrics, \\\"Unconstrained model\\\", \\\"orange\\\")\\nplot_age_recall_barplot(\\n    new_model_metrics,\\n    \\\"Constrained model with proxy Lagrangian recall constraints using TFCO\\\",\\n    \\\"blue\\\",\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_age_recall_barplot(model_metrics, title=\"barplot\", color=\"blue\"):\n",
    "    plt.bar(range(len(model_metrics)), [val[1] for val in model_metrics], color=color)\n",
    "    plt.xticks(range(len(model_metrics)), [int(val[0]) for val in model_metrics])\n",
    "    plt.xticks(rotation=70)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_age_recall_barplot(orig_model_metrics, \"Unconstrained model\", \"orange\")\n",
    "plot_age_recall_barplot(\n",
    "    new_model_metrics,\n",
    "    \"Constrained model with proxy Lagrangian recall constraints using TFCO\",\n",
    "    \"blue\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 48;\n",
       "                var nbb_unformatted_code = \"# Plot data side by side on the same graph.\\n\\n# Put the data into one dataframe to plot them side-by-side\\nage = list(zip(*orig_model_metrics))[0]\\noriginal_model_metrics = list(zip(*orig_model_metrics))[1]\\nconstrained_model_metrics = list(zip(*new_model_metrics))[1]\\nplot_df = pd.DataFrame(\\n    {\\n        \\\"Age\\\": age,\\n        \\\"Original Model\\\": original_model_metrics,\\n        \\\"Constrained Model\\\": constrained_model_metrics,\\n    },\\n)\\nplot_df[\\\"Age\\\"] = plot_df[\\\"Age\\\"].astype(int)\\nplot_df = plot_df.set_index(\\\"Age\\\")\\n\\n# Draw barplot of the original and optimized data for each age-group.\\nax = plot_df.plot(\\n    kind=\\\"bar\\\",\\n    figsize=(10, 6),\\n    title=\\\"Recall graph for original and optimized model\\\",\\n    xlabel=\\\"Age\\\",\\n    ylabel=\\\"Recall\\\",\\n    ylim=(0.6, 1.4),\\n)\\n\\n# Add horizontal lines for baseline recall, original recall and optimized recall\\noriginal_recall = calculate_model_metrics_for_age(model, 99)[0][2]\\nnew_recall = calculate_model_metrics_for_age(model_constrained, 99)[0][2]\\nbaseline_recall = 0.9\\nplt.axhline(\\n    y=original_recall, color=\\\"blue\\\", linestyle=\\\"dashed\\\", label=\\\"Original total recall\\\"\\n)\\nplt.axhline(\\n    y=new_recall, color=\\\"orange\\\", linestyle=\\\"dashed\\\", label=\\\"optimized total recall\\\"\\n)\\nplt.axhline(\\n    y=baseline_recall, color=\\\"red\\\", linestyle=\\\"dashed\\\", label=\\\"baseline total recall\\\"\\n)\\n\\n# Draw the plots\\nplt.legend()\\nplt.show()\";\n",
       "                var nbb_formatted_code = \"# Plot data side by side on the same graph.\\n\\n# Put the data into one dataframe to plot them side-by-side\\nage = list(zip(*orig_model_metrics))[0]\\noriginal_model_metrics = list(zip(*orig_model_metrics))[1]\\nconstrained_model_metrics = list(zip(*new_model_metrics))[1]\\nplot_df = pd.DataFrame(\\n    {\\n        \\\"Age\\\": age,\\n        \\\"Original Model\\\": original_model_metrics,\\n        \\\"Constrained Model\\\": constrained_model_metrics,\\n    },\\n)\\nplot_df[\\\"Age\\\"] = plot_df[\\\"Age\\\"].astype(int)\\nplot_df = plot_df.set_index(\\\"Age\\\")\\n\\n# Draw barplot of the original and optimized data for each age-group.\\nax = plot_df.plot(\\n    kind=\\\"bar\\\",\\n    figsize=(10, 6),\\n    title=\\\"Recall graph for original and optimized model\\\",\\n    xlabel=\\\"Age\\\",\\n    ylabel=\\\"Recall\\\",\\n    ylim=(0.6, 1.4),\\n)\\n\\n# Add horizontal lines for baseline recall, original recall and optimized recall\\noriginal_recall = calculate_model_metrics_for_age(model, 99)[0][2]\\nnew_recall = calculate_model_metrics_for_age(model_constrained, 99)[0][2]\\nbaseline_recall = 0.9\\nplt.axhline(\\n    y=original_recall, color=\\\"blue\\\", linestyle=\\\"dashed\\\", label=\\\"Original total recall\\\"\\n)\\nplt.axhline(\\n    y=new_recall, color=\\\"orange\\\", linestyle=\\\"dashed\\\", label=\\\"optimized total recall\\\"\\n)\\nplt.axhline(\\n    y=baseline_recall, color=\\\"red\\\", linestyle=\\\"dashed\\\", label=\\\"baseline total recall\\\"\\n)\\n\\n# Draw the plots\\nplt.legend()\\nplt.show()\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot data side by side on the same graph.\n",
    "\n",
    "# Put the data into one dataframe to plot them side-by-side\n",
    "age = list(zip(*orig_model_metrics))[0]\n",
    "original_model_metrics = list(zip(*orig_model_metrics))[1]\n",
    "constrained_model_metrics = list(zip(*new_model_metrics))[1]\n",
    "plot_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Age\": age,\n",
    "        \"Original Model\": original_model_metrics,\n",
    "        \"Constrained Model\": constrained_model_metrics,\n",
    "    },\n",
    ")\n",
    "plot_df[\"Age\"] = plot_df[\"Age\"].astype(int)\n",
    "plot_df = plot_df.set_index(\"Age\")\n",
    "\n",
    "# Draw barplot of the original and optimized data for each age-group.\n",
    "ax = plot_df.plot(\n",
    "    kind=\"bar\",\n",
    "    figsize=(10, 6),\n",
    "    title=\"Recall graph for original and optimized model\",\n",
    "    xlabel=\"Age\",\n",
    "    ylabel=\"Recall\",\n",
    "    ylim=(0.6, 1.4),\n",
    ")\n",
    "\n",
    "# Add horizontal lines for baseline recall, original recall and optimized recall\n",
    "original_recall = calculate_model_metrics_for_age(model, 99)[0][2]\n",
    "new_recall = calculate_model_metrics_for_age(model_constrained, 99)[0][2]\n",
    "baseline_recall = 0.9\n",
    "plt.axhline(\n",
    "    y=original_recall, color=\"blue\", linestyle=\"dashed\", label=\"Original total recall\"\n",
    ")\n",
    "plt.axhline(\n",
    "    y=new_recall, color=\"orange\", linestyle=\"dashed\", label=\"optimized total recall\"\n",
    ")\n",
    "plt.axhline(\n",
    "    y=baseline_recall, color=\"red\", linestyle=\"dashed\", label=\"baseline total recall\"\n",
    ")\n",
    "\n",
    "# Draw the plots\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can conclude from the above results comparing the original unconstrained and new recall-constrained model, that the directly optimizing for recall to be above 0.90 using the TFCO's lagrangian optimizer made a significant improvement in improving the recall of the age group < 30. The key benefit is that the recall was uniformly kept high above 90% over the different age groups.\n",
    "\n",
    "The study meets its objectives:\n",
    "1. Demonstrate that naive training can result in some subsets of the data having poor results. In this case, the lower age groups have low recall. Low recall can result in missed early diagnosis of Kidney Disease and potential loss of life.\n",
    "2. Demonstrate that explicit optimizing for recall for subsets such as lower or higher ages can result in a more reliable model with better results across all the targeted sub-categories.\n",
    "3. Use Lagrange-based proxy optimizers to control for age sub-group results in consistent high results above 90% recall.\n",
    "4. This is a very general approach which can be applied to most machine learning models. Hence it can be used broadly in the multiple medical ML studies to yield more reliable models.\n",
    "\n",
    "Overall, the result of the new model compared to the old model is very clear and results in a recall over 0.90 over all age groups, which is a huge and life-saving improvement of the model. This was achieved as a direct result of optimizing for a target value of recall during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
